{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true,
      "collapsed_sections": [
        "CtE9vfe7TKD9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa90bbe246da435894092b3a5158b56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_766d9ec09be14714b714d23444c41a1b",
              "IPY_MODEL_ccd8aba47cd84c13895a0c4b8572b930",
              "IPY_MODEL_4b65f1a444fc44fc890e5fba6abff13f"
            ],
            "layout": "IPY_MODEL_1e85630d2d9c4208bba52a53bbcded0e"
          }
        },
        "766d9ec09be14714b714d23444c41a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90928b6e1efa498b8e21375c91decd70",
            "placeholder": "​",
            "style": "IPY_MODEL_09b6515af05e45cf9e9634f2a0119955",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ccd8aba47cd84c13895a0c4b8572b930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df80b12d28a9442989c0436480b1d351",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b3f0b0a58ad46dea3f035a7afadc1e8",
            "value": 2
          }
        },
        "4b65f1a444fc44fc890e5fba6abff13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b5178a1f8924cfbb3b5efe087406596",
            "placeholder": "​",
            "style": "IPY_MODEL_b2fc4f673402410bb9159974b2dc3d2f",
            "value": " 2/2 [00:01&lt;00:00,  1.51s/it]"
          }
        },
        "1e85630d2d9c4208bba52a53bbcded0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90928b6e1efa498b8e21375c91decd70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b6515af05e45cf9e9634f2a0119955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df80b12d28a9442989c0436480b1d351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3f0b0a58ad46dea3f035a7afadc1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b5178a1f8924cfbb3b5efe087406596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2fc4f673402410bb9159974b2dc3d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d3348a8b4bc41a8b8428f64cfa783a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4047c65b5264b9baa3eee7ab08d5e1f",
              "IPY_MODEL_7348dc2b42694cc5bc79836402d0ae40",
              "IPY_MODEL_579c1c9652f74ef8a99cb24cd5310481"
            ],
            "layout": "IPY_MODEL_80b4a63993af4d708004221ee609587f"
          }
        },
        "e4047c65b5264b9baa3eee7ab08d5e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53466267c6504e81af1543d8d4ecf949",
            "placeholder": "​",
            "style": "IPY_MODEL_395ea9816f39402cbdcc0fad6850fb7a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "7348dc2b42694cc5bc79836402d0ae40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9355e98807145428869fce26526716a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eae063bb8c5c48ad95e63cbc49ffabb5",
            "value": 2
          }
        },
        "579c1c9652f74ef8a99cb24cd5310481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_309d9d6fe1f14c17a43746055bf8bb07",
            "placeholder": "​",
            "style": "IPY_MODEL_8745a14fd5ba4f0db8b27c8266c85cba",
            "value": " 2/2 [00:01&lt;00:00,  1.07s/it]"
          }
        },
        "80b4a63993af4d708004221ee609587f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53466267c6504e81af1543d8d4ecf949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395ea9816f39402cbdcc0fad6850fb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9355e98807145428869fce26526716a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae063bb8c5c48ad95e63cbc49ffabb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "309d9d6fe1f14c17a43746055bf8bb07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8745a14fd5ba4f0db8b27c8266c85cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd26ff78ff5f44029175424f0d4a13de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80f3c9e15cfa498695d7559c00a20cdd",
              "IPY_MODEL_582e921d5506441cae0201135e1a4cc2",
              "IPY_MODEL_92cd7a9e138b40b9934dcb6b4579c057"
            ],
            "layout": "IPY_MODEL_8bac813fb8f94dda9852780e26ada314"
          }
        },
        "80f3c9e15cfa498695d7559c00a20cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac90319ce3b64d7f914a2e0a6667c07f",
            "placeholder": "​",
            "style": "IPY_MODEL_b4d1e5edd492478bb9a37beb40348a48",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "582e921d5506441cae0201135e1a4cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d727cef20dfa46bd889aba4b87b844cd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2551f3a2d5e4e7c904cb7a1e16d2bf9",
            "value": 2
          }
        },
        "92cd7a9e138b40b9934dcb6b4579c057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecadf3d681104f19ae28469679e02f3d",
            "placeholder": "​",
            "style": "IPY_MODEL_cb35f026286d4cfda3ece6dabd9fe9b4",
            "value": " 2/2 [00:01&lt;00:00,  1.48s/it]"
          }
        },
        "8bac813fb8f94dda9852780e26ada314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac90319ce3b64d7f914a2e0a6667c07f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4d1e5edd492478bb9a37beb40348a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d727cef20dfa46bd889aba4b87b844cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2551f3a2d5e4e7c904cb7a1e16d2bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecadf3d681104f19ae28469679e02f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb35f026286d4cfda3ece6dabd9fe9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Environment detection and dependency installation**"
      ],
      "metadata": {
        "id": "nXZYjoNp6OGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Google Colab installs (if running in Google Colab)\n",
        "import os\n",
        "\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "    print(\"[INFO] Running in Google Colab, installing requirements.\")\n",
        "    !pip install -U torch # requires torch 2.1.1+ (for efficient sdpa implementation)\n",
        "    !pip install tqdm # for progress bars\n",
        "    !pip install sentence-transformers # for embedding models\n",
        "    !pip install accelerate # for quantization model loading\n",
        "    !pip install bitsandbytes # for quantizing models (less storage space)\n",
        "#     !pip install flash-attn --no-build-isolation # for faster attention mechanism = faster LLM inference"
      ],
      "metadata": {
        "id": "tifg1MHarvix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22208ba2-c327-455a-ae24-589696952a43",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Running in Google Colab, installing requirements.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (79.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=1.11.0->sentence-transformers) (79.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (79.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch<3,>=2.0->bitsandbytes) (79.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Import libraries**"
      ],
      "metadata": {
        "id": "oZUU3GnN6NSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from spacy.lang.en import English\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "import numpy as np\n",
        "re.compile('<title>(.*)title>')"
      ],
      "metadata": {
        "id": "eTfMK3Qzuidz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2307bace-bc46-40df-fd0b-46eadcc7b466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'<title>(.*)title>', re.UNICODE)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Input**"
      ],
      "metadata": {
        "id": "oVaXFpSC6XOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get TEXT document\n",
        "text_path = pd.read_csv(\"IELTS.txt\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "0AcSc3mCv16X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_path"
      ],
      "metadata": {
        "id": "WrpMSmapv4or",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "da5df3a5-7c65-4396-89ec-8062022836c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Skip to main content\n",
              "0                              Texts\n",
              "1                              Video\n",
              "2                              Audio\n",
              "3                           Software\n",
              "4                             Images\n",
              "...                              ...\n",
              "19926     University Printing House \n",
              "19927              Shaftesbury Road \n",
              "19928             Cambridge CB2 8BS \n",
              "19929                            UK \n",
              "19930  cambridgeexams@cambridge.org \n",
              "\n",
              "[19931 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ddb704-4608-4220-9ba5-75628cbd540d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Skip to main content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Texts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Audio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Software</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Images</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19926</th>\n",
              "      <td>University Printing House</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19927</th>\n",
              "      <td>Shaftesbury Road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19928</th>\n",
              "      <td>Cambridge CB2 8BS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19929</th>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19930</th>\n",
              "      <td>cambridgeexams@cambridge.org</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19931 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ddb704-4608-4220-9ba5-75628cbd540d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1ddb704-4608-4220-9ba5-75628cbd540d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1ddb704-4608-4220-9ba5-75628cbd540d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8a73563f-fe31-49e2-a221-c6003d3ee78a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a73563f-fe31-49e2-a221-c6003d3ee78a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8a73563f-fe31-49e2-a221-c6003d3ee78a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "text_path",
              "summary": "{\n  \"name\": \"text_path\",\n  \"rows\": 19931,\n  \"fields\": [\n    {\n      \"column\": \"Skip to main content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17950,\n        \"samples\": [\n          \"giant, Thank yon lor making us look and sound great! \",\n          \"equivaleni of a couple oE dcp hams . which is simply amazing - \",\n          \"A; Ami could you Sell me whai you do for a living? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def open_and_read_txt(txt_path: str) -> list[dict]:\n",
        "\n",
        "    pages_and_texts = []\n",
        "\n",
        "    # Open a text file and read it line by line\n",
        "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line_number, line in enumerate(lines):\n",
        "        text = line.strip()  # Remove extra whitespace characters\n",
        "        pages_and_texts.append({\n",
        "            \"line_number\": line_number + 1,  # Current line number, starting from 1\n",
        "            \"line_char_count\": len(text),  # Number of characters\n",
        "            \"line_word_count\": len(text.split(\" \")),  # Number of words\n",
        "            \"line_sentence_count_raw\": len(text.split(\". \")),  # Number of sentences\n",
        "            \"line_token_count\": len(text) / 4,  # Estimated number of tokens (1 token is about 4 characters)\n",
        "            \"text\": text  # The text content of the current line\n",
        "        })\n",
        "\n",
        "    return pages_and_texts\n",
        "\n",
        "\n",
        "# Call the function to read the IELTS.txt file\n",
        "txt_path = \"IELTS.txt\"\n",
        "lines_and_texts = open_and_read_txt(txt_path)\n",
        "\n",
        "# View the results of the first two rows\n",
        "lines_and_texts[:2]"
      ],
      "metadata": {
        "id": "IXK_-aTxwWs1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25660b9e-fcf5-4748-c670-dc40c854467c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 1,\n",
              "  'line_char_count': 20,\n",
              "  'line_word_count': 4,\n",
              "  'line_sentence_count_raw': 1,\n",
              "  'line_token_count': 5.0,\n",
              "  'text': 'Skip to main content'},\n",
              " {'line_number': 2,\n",
              "  'line_char_count': 0,\n",
              "  'line_word_count': 1,\n",
              "  'line_sentence_count_raw': 1,\n",
              "  'line_token_count': 0.0,\n",
              "  'text': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(lines_and_texts, k=3)"
      ],
      "metadata": {
        "id": "QlcPwYTMxfnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbe3d05-8c31-43ba-b12a-8ff50f0b1afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 3075,\n",
              "  'line_char_count': 0,\n",
              "  'line_word_count': 1,\n",
              "  'line_sentence_count_raw': 1,\n",
              "  'line_token_count': 0.0,\n",
              "  'text': ''},\n",
              " {'line_number': 3155,\n",
              "  'line_char_count': 0,\n",
              "  'line_word_count': 1,\n",
              "  'line_sentence_count_raw': 1,\n",
              "  'line_token_count': 0.0,\n",
              "  'text': ''},\n",
              " {'line_number': 24954,\n",
              "  'line_char_count': 0,\n",
              "  'line_word_count': 1,\n",
              "  'line_sentence_count_raw': 1,\n",
              "  'line_token_count': 0.0,\n",
              "  'text': ''}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(lines_and_texts)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tuVSi5xFxrRE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ca5c24ad-5e92-4fa8-f269-0ed5902e826e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   line_number  line_char_count  line_word_count  line_sentence_count_raw  \\\n",
              "0            1               20                4                        1   \n",
              "1            2                0                1                        1   \n",
              "2            3                5                1                        1   \n",
              "3            4                0                1                        1   \n",
              "4            5                5                1                        1   \n",
              "\n",
              "   line_token_count                  text  \n",
              "0              5.00  Skip to main content  \n",
              "1              0.00                        \n",
              "2              1.25                 Texts  \n",
              "3              0.00                        \n",
              "4              1.25                 Video  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61e4ea1f-08a8-48d4-a92a-037cd159f54a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line_number</th>\n",
              "      <th>line_char_count</th>\n",
              "      <th>line_word_count</th>\n",
              "      <th>line_sentence_count_raw</th>\n",
              "      <th>line_token_count</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5.00</td>\n",
              "      <td>Skip to main content</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.25</td>\n",
              "      <td>Texts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.25</td>\n",
              "      <td>Video</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61e4ea1f-08a8-48d4-a92a-037cd159f54a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61e4ea1f-08a8-48d4-a92a-037cd159f54a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61e4ea1f-08a8-48d4-a92a-037cd159f54a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f66ece54-7354-47d4-a5e0-eec7615bc608\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f66ece54-7354-47d4-a5e0-eec7615bc608')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f66ece54-7354-47d4-a5e0-eec7615bc608 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40321,\n  \"fields\": [\n    {\n      \"column\": \"line_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11639,\n        \"min\": 1,\n        \"max\": 40321,\n        \"num_unique_values\": 40321,\n        \"samples\": [\n          20037,\n          25487,\n          5870\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 0,\n        \"max\": 117,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          74,\n          6,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 32,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          26,\n          15,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_sentence_count_raw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.6520834176833095,\n        \"min\": 0.0,\n        \"max\": 29.25,\n        \"num_unique_values\": 117,\n        \"samples\": [\n          18.5,\n          1.5,\n          9.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18714,\n        \"samples\": [\n          \"2.535\",\n          \"ihat, Urn, [fie Information says she'll need just a jar for\",\n          \"George: Ves it dues - but I'm sure it'll go quickly. Vou know\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get stats\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "-zKTDBGHx_XS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "507dc3a4-9e72-499b-810e-b1b1a28c4a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       line_number  line_char_count  line_word_count  line_sentence_count_raw  \\\n",
              "count     40321.00         40321.00         40321.00                 40321.00   \n",
              "mean      20161.00            20.31             4.24                     1.09   \n",
              "std       11639.81            26.61             4.55                     0.31   \n",
              "min           1.00             0.00             1.00                     1.00   \n",
              "25%       10081.00             0.00             1.00                     1.00   \n",
              "50%       20161.00             3.00             1.00                     1.00   \n",
              "75%       30241.00            42.00             7.00                     1.00   \n",
              "max       40321.00           117.00            32.00                     6.00   \n",
              "\n",
              "       line_token_count  \n",
              "count          40321.00  \n",
              "mean               5.08  \n",
              "std                6.65  \n",
              "min                0.00  \n",
              "25%                0.00  \n",
              "50%                0.75  \n",
              "75%               10.50  \n",
              "max               29.25  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c984b60-dd96-406f-bcfa-5db4dd9a312a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>line_number</th>\n",
              "      <th>line_char_count</th>\n",
              "      <th>line_word_count</th>\n",
              "      <th>line_sentence_count_raw</th>\n",
              "      <th>line_token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40321.00</td>\n",
              "      <td>40321.00</td>\n",
              "      <td>40321.00</td>\n",
              "      <td>40321.00</td>\n",
              "      <td>40321.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>20161.00</td>\n",
              "      <td>20.31</td>\n",
              "      <td>4.24</td>\n",
              "      <td>1.09</td>\n",
              "      <td>5.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11639.81</td>\n",
              "      <td>26.61</td>\n",
              "      <td>4.55</td>\n",
              "      <td>0.31</td>\n",
              "      <td>6.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10081.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>20161.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>30241.00</td>\n",
              "      <td>42.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>10.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>40321.00</td>\n",
              "      <td>117.00</td>\n",
              "      <td>32.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>29.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c984b60-dd96-406f-bcfa-5db4dd9a312a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0c984b60-dd96-406f-bcfa-5db4dd9a312a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0c984b60-dd96-406f-bcfa-5db4dd9a312a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7109f59a-c6d0-4298-a4f5-6c0501f40ef7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7109f59a-c6d0-4298-a4f5-6c0501f40ef7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7109f59a-c6d0-4298-a4f5-6c0501f40ef7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"line_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14531.57911849268,\n        \"min\": 1.0,\n        \"max\": 40321.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          40321.0,\n          20161.0,\n          30241.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14245.126092243421,\n        \"min\": 0.0,\n        \"max\": 40321.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          40321.0,\n          20.31,\n          42.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14253.064719083037,\n        \"min\": 1.0,\n        \"max\": 40321.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          40321.0,\n          4.24,\n          32.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_sentence_count_raw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14255.05058899777,\n        \"min\": 0.31,\n        \"max\": 40321.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.09,\n          6.0,\n          0.31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"line_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14252.991489632663,\n        \"min\": 0.0,\n        \"max\": 40321.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          40321.0,\n          5.08,\n          10.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Data and text processing**"
      ],
      "metadata": {
        "id": "r4T9iBgRnIDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Use spaCy and tqdm for sentence segmentation and statistics on text**"
      ],
      "metadata": {
        "id": "3vu4hHpk-gcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English # see https://spacy.io/usage for install instructions\n",
        "\n",
        "nlp = English()\n",
        "\n",
        "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "# Create a document instance as an example\n",
        "doc = nlp(\"This is a sentence. This another sentence.\")\n",
        "assert len(list(doc.sents)) == 2\n",
        "\n",
        "# Access the sentences of the document\n",
        "list(doc.sents)"
      ],
      "metadata": {
        "id": "IaGCj26TynGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c91607-2c93-447a-a814-b3122050a4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[This is a sentence., This another sentence.]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Initialize the English model of spaCy\n",
        "nlp = English()\n",
        "nlp.add_pipe(\"sentencizer\")  # Add the sentencizer to the spaCy processing pipeline\n",
        "\n",
        "# Step 3: Split the text column of the dataset into sentences\n",
        "pages_and_texts = [{\"text\": str(row[0]).strip()} for row in text_path.values]  # Extract the text column\n",
        "\n",
        "# Step 4: Iterate over each row of text, split it into sentences, and count the number of sentences\n",
        "for item in tqdm(pages_and_texts):\n",
        "    # Use spaCy to split sentences\n",
        "    item[\"sentences\"] = list(nlp(item[\"text\"]).sents)\n",
        "\n",
        "    # Ensure sentences are in string format\n",
        "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
        "\n",
        "    # Count the number of sentences\n",
        "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])\n",
        "\n",
        "# Step 5: View the results (for example, the first two rows)\n",
        "for page in pages_and_texts[:2]:\n",
        "    print(page)"
      ],
      "metadata": {
        "id": "6GOrUgBnzjQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94af8fb5-60ec-4f60-ba30-7d740911d7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19931/19931 [00:02<00:00, 8967.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Texts', 'sentences': ['Texts'], 'page_sentence_count_spacy': 1}\n",
            "{'text': 'Video', 'sentences': ['Video'], 'page_sentence_count_spacy': 1}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect an example\n",
        "random.sample(pages_and_texts, k=1)"
      ],
      "metadata": {
        "id": "2XwMvRH-G8ly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2159881f-d8e3-456d-d716-754d6279d718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': 'C', 'sentences': ['C'], 'page_sentence_count_spacy': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "rKIwGVbUHWCr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "21cb0c33-01f4-4a47-8480-ad33a5a629a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       page_sentence_count_spacy\n",
              "count                   19931.00\n",
              "mean                        1.19\n",
              "std                         2.12\n",
              "min                         1.00\n",
              "25%                         1.00\n",
              "50%                         1.00\n",
              "75%                         1.00\n",
              "max                       295.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bc208dc-ca09-4a56-93cc-8a3600a31af9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_sentence_count_spacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19931.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>295.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bc208dc-ca09-4a56-93cc-8a3600a31af9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8bc208dc-ca09-4a56-93cc-8a3600a31af9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8bc208dc-ca09-4a56-93cc-8a3600a31af9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0b2926a-7ce3-4880-b004-3f42e17469ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0b2926a-7ce3-4880-b004-3f42e17469ed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0b2926a-7ce3-4880-b004-3f42e17469ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"page_sentence_count_spacy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7032.155143299014,\n        \"min\": 1.0,\n        \"max\": 19931.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.19,\n          295.0,\n          2.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Chunking ten sentences together**"
      ],
      "metadata": {
        "id": "Cb0x5XHIIBpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define split size to turn groups of sentences into chunks\n",
        "num_sentence_chunk_size = 10\n",
        "\n",
        "# Create a function that recursively splits a list into desired sizes\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int) -> list[list[str]]:\n",
        "    \"\"\"\n",
        "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
        "\n",
        "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
        "    \"\"\"\n",
        "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
        "\n",
        "# Loop through pages and texts and split sentences into chunks\n",
        "for item in tqdm(pages_and_texts):\n",
        "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
        "                                         slice_size=num_sentence_chunk_size)\n",
        "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
      ],
      "metadata": {
        "id": "CT5m-guBHis6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8601a203-d698-4c0e-fce7-4c9150f9faf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19931/19931 [00:00<00:00, 680671.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
        "random.sample(pages_and_texts, k=1)"
      ],
      "metadata": {
        "id": "OV6-VCi8HlHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c0dc67-57b0-44f9-9db1-17ba5a4509a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'text': \"fh ii ii really doesn't suit ihe way we work these* days. Its\",\n",
              "  'sentences': [\"fh ii ii really doesn't suit ihe way we work these* days.\",\n",
              "   'Its'],\n",
              "  'page_sentence_count_spacy': 2,\n",
              "  'sentence_chunks': [[\"fh ii ii really doesn't suit ihe way we work these* days.\",\n",
              "    'Its']],\n",
              "  'num_chunks': 1}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to get stats\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "S0GpOfF-Hn15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a0180ac4-f413-4dc9-94fb-da21325f4906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       page_sentence_count_spacy  num_chunks\n",
              "count                   19931.00    19931.00\n",
              "mean                        1.19        1.00\n",
              "std                         2.12        0.21\n",
              "min                         1.00        1.00\n",
              "25%                         1.00        1.00\n",
              "50%                         1.00        1.00\n",
              "75%                         1.00        1.00\n",
              "max                       295.00       30.00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28089a1c-a5b9-4725-aefd-5e7298ae0a9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_sentence_count_spacy</th>\n",
              "      <th>num_chunks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19931.00</td>\n",
              "      <td>19931.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.19</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.12</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>295.00</td>\n",
              "      <td>30.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28089a1c-a5b9-4725-aefd-5e7298ae0a9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28089a1c-a5b9-4725-aefd-5e7298ae0a9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28089a1c-a5b9-4725-aefd-5e7298ae0a9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a70c9e93-9e2e-468d-8b23-364f32df8818\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a70c9e93-9e2e-468d-8b23-364f32df8818')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a70c9e93-9e2e-468d-8b23-364f32df8818 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"page_sentence_count_spacy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7032.155143299014,\n        \"min\": 1.0,\n        \"max\": 19931.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.19,\n          295.0,\n          2.12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_chunks\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7044.901634957494,\n        \"min\": 0.21,\n        \"max\": 19931.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1.0,\n          30.0,\n          19931.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Splitting each chunk into its own item**"
      ],
      "metadata": {
        "id": "tGe27KSSIJo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list to store information about each sentence chunk\n",
        "pages_and_chunks = []\n",
        "\n",
        "# Iterate over each text block\n",
        "for item in tqdm(pages_and_texts):\n",
        "    for sentence_chunk in item[\"sentence_chunks\"]:  # Iterate over each chunk\n",
        "        chunk_dict = {}  # Store information about the current chunk\n",
        "\n",
        "        # Optionally, add page number information\n",
        "        chunk_dict[\"page_number\"] = item.get(\"page_number\", None)  # Default to None if no page number\n",
        "\n",
        "        # Join the sentences in the chunk into a single string\n",
        "        joined_sentence_chunk = \" \".join(sentence_chunk).replace(\"\\n\", \" \").strip()\n",
        "        # Regular expression replacement: replace \". A\" with \".\\nA\" to handle sentence separators\n",
        "        joined_sentence_chunk = re.sub(r\"\\. ([A-Z])\", r\". \\1\", joined_sentence_chunk)\n",
        "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
        "\n",
        "        # Gather statistics about the chunk\n",
        "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)  # Character count\n",
        "        chunk_dict[\"chunk_word_count\"] = len(joined_sentence_chunk.split(\" \"))  # Word count\n",
        "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4  # Estimate token count (1 token ≈ 4 characters)\n",
        "\n",
        "        # Add the current chunk to the list\n",
        "        pages_and_chunks.append(chunk_dict)\n",
        "\n",
        "# View statistics: how many chunks there are\n",
        "print(f\"Total chunks: {len(pages_and_chunks)}\")\n",
        "\n",
        "# Example print of the first two chunks\n",
        "for chunk in pages_and_chunks[:2]:\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "id": "F-T7PGRqIIWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e7217c-d556-4dd3-86e8-450d8a4e6f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19931/19931 [00:00<00:00, 254172.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 19960\n",
            "{'page_number': None, 'sentence_chunk': 'Texts', 'chunk_char_count': 5, 'chunk_word_count': 1, 'chunk_token_count': 1.25}\n",
            "{'page_number': None, 'sentence_chunk': 'Video', 'chunk_char_count': 5, 'chunk_word_count': 1, 'chunk_token_count': 1.25}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random sample\n",
        "random.sample(pages_and_chunks, k=1)"
      ],
      "metadata": {
        "id": "XEHJowp6KIzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8499c83d-1163-46a6-c7d5-39031457907c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': None,\n",
              "  'sentence_chunk': 'Test Tip Pay attention',\n",
              "  'chunk_char_count': 22,\n",
              "  'chunk_word_count': 4,\n",
              "  'chunk_token_count': 5.5}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've broken our whole textbook into chunks of 10 sentences or less as well as the page number they came from."
      ],
      "metadata": {
        "id": "bRwjoJ2KKSRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get stats about our chunks\n",
        "df = pd.DataFrame(pages_and_chunks)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "tcTnwJuEKTHS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "a314d1cf-a5c8-46d3-912a-850d4884d917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       chunk_char_count  chunk_word_count  chunk_token_count\n",
              "count          19960.00          19960.00           19960.00\n",
              "mean              41.26              7.67              10.31\n",
              "std               58.21             11.59              14.55\n",
              "min                1.00              1.00               0.25\n",
              "25%               16.00              3.00               4.00\n",
              "50%               41.00              7.00              10.25\n",
              "75%               60.00             11.00              15.00\n",
              "max             2346.00            438.00             586.50"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7c73b02-289c-417f-a202-de7a849a22f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk_char_count</th>\n",
              "      <th>chunk_word_count</th>\n",
              "      <th>chunk_token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>19960.00</td>\n",
              "      <td>19960.00</td>\n",
              "      <td>19960.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>41.26</td>\n",
              "      <td>7.67</td>\n",
              "      <td>10.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>58.21</td>\n",
              "      <td>11.59</td>\n",
              "      <td>14.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>41.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>10.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>15.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2346.00</td>\n",
              "      <td>438.00</td>\n",
              "      <td>586.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7c73b02-289c-417f-a202-de7a849a22f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f7c73b02-289c-417f-a202-de7a849a22f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f7c73b02-289c-417f-a202-de7a849a22f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-51e57078-0384-4386-8c63-29f1679f923f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-51e57078-0384-4386-8c63-29f1679f923f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-51e57078-0384-4386-8c63-29f1679f923f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"chunk_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6974.469843513837,\n        \"min\": 1.0,\n        \"max\": 19960.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          41.26,\n          41.0,\n          19960.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7034.338211217375,\n        \"min\": 1.0,\n        \"max\": 19960.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          7.67,\n          7.0,\n          19960.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7027.46466455669,\n        \"min\": 0.25,\n        \"max\": 19960.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10.31,\n          10.25,\n          19960.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here,because we foung that Chunks that are too short (token count ≤ 30) may lack sufficient contextual information, resulting in embeddings generated that are not meaningful enough.So,we selcet token_length more than 30."
      ],
      "metadata": {
        "id": "ksXdNAHYHtar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Select token_length >30**"
      ],
      "metadata": {
        "id": "dWpPbbE4HauT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show random chunks with under 30 tokens in length\n",
        "min_token_length = 30\n",
        "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
        "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
      ],
      "metadata": {
        "id": "TrDxm-P7KfmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54193325-f7d7-448c-b4cf-64a713e5486d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk token count: 1.75 | Text: Writing\n",
            "Chunk token count: 3.25 | Text: party starter\n",
            "Chunk token count: 2.75 | Text: attach it):\n",
            "Chunk token count: 14.25 | Text: It seems chat no amount of warning ugns or S|>ecd cameras\n",
            "Chunk token count: 5.75 | Text: Choose TWO letters. A-E\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm looks like some of our chunks have quite a low token count.\n",
        "\n",
        "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?"
      ],
      "metadata": {
        "id": "4yQviwdqKsaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
        "pages_and_chunks_over_min_token_len[:2]"
      ],
      "metadata": {
        "id": "76nk51HHKq9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3207be27-e8f0-46e2-c791-d93f1cb7096d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'page_number': None,\n",
              "  'sentence_chunk': '[fudging from] the complexity of the material that has been collected from different parts of the landscape \\r and brought to the site, they | the people] must have had an elementary knowledge of chemistry to be able to \\r combine these materials to produce ibis form. Its not a straightforward process,™ said Henshilwood. \\r \\r \\r 1 *2 Scanning involves searching a text quickly for a specific piece \\r of information. Practise scanning the passage for the words/ \\r numbers in the box. \\r \\r \\r 75,000 100,000 200,000 artefacts ochre \\r \\r \\r 48 \\r \\r \\r \\r \\r \\r \\r \\r \\r Reading skills \\r \\r \\r 2 Using words from the passage \\r \\r Their are several types of question that ask you to write a word and/or \\r number from the passage. \\r \\r * You will be told the maximum number of words to write. \\r \\r * You must only write words that are in the passage. Make sure you \\r copy the spelling correctly, \\r \\r 1 ^ ^ need to change the words in the passage and you do not \\r need to join words together. \\r \\r II um w rite tuo many words or make a spelling mistake, your answer \\r wilt he marked wrong. \\r \\r Test Tip if the question asks you to write TWO WORDS AND/OR A \\r NUMBER, this means the answer may be: \\r \\r * one word \\r \\r * one word + a number \\r ■ two words \\r \\r * two words + a number \\r \\r Remember that even if a number is written as a word, it counts as a \\r number (e.g. twenty five trees = one word and a number).',\n",
              "  'chunk_char_count': 1381,\n",
              "  'chunk_word_count': 293,\n",
              "  'chunk_token_count': 345.25},\n",
              " {'page_number': None,\n",
              "  'sentence_chunk': 'You do not \\r need to write full sentences or join words together, For example: \\r \\r Answer the question with NO MORE THAN TWO WORDS from \\r the reading passage. \\r \\r What TWO colours did the painter use? \\r \\r (Answer: black, white not bhdi ond white ) \\r \\r tailieutienganh.net | IELTS materials \\r \\r Short answer questions and sentence completion tasks \\r \\r Short answer questions test your ability to find specific details in a \\r passage. Use the words in the questions to: \\r \\r ■ help locate the relevant part of the passage \\r * find out exactly what details you are looking for. \\r \\r 2.1 In questions 1-3 below, the key words that you need to locate in \\r the passage are in bold, and the details you need to find out arc \\r underlined. Use these words to help you locate the relevant parts \\r of the text and then answer the questions. \\r \\r \\r Choose WO MORE THAN TWO WORDS AND/OR A NUMBER from the passage \\r for each answer. \\r \\r 1 Which of the artefacts mentioned are the oldest ? \\r \\r 2 When was the material Henshilwood found originally made ? \\r \\r 3 What two common materials did ancient humans use to obtain their ochre?',\n",
              "  'chunk_char_count': 1113,\n",
              "  'chunk_word_count': 220,\n",
              "  'chunk_token_count': 278.25}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Embedding our text chunks**\n",
        "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order)."
      ],
      "metadata": {
        "id": "JEkBLWj3POAT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install sentence-transformers"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6FOXgJT0LJUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25f8b9e4-9e0f-41bb-ee70-a3814589d5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=1.11.0->sentence-transformers) (79.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade --force-reinstall torchvision torchaudio torchtext torch"
      ],
      "metadata": {
        "id": "JkhVcMR641Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",device=\"cpu\") # choose the device to load the model to (note: GPU will often be *much* faster than CPU)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kmjcYhyPP7WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1652207-1314-4ed1-dc19-c65269d53564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we add an embedding field to each of our chunk items in Single processing?"
      ],
      "metadata": {
        "id": "HCCjtw1uRyAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Send the model to the GPU\n",
        "embedding_model.to(\"cuda\") # requires a GPU installed, for reference on my local machine, I'm using a NVIDIA RTX 4090\n",
        "\n",
        "# Create embeddings one by one on the GPU\n",
        "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
        "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
      ],
      "metadata": {
        "id": "gCoaZLjZRyl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2680d11c-eb49-45e1-fbc1-6591c32e7785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [00:01<00:00, 24.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.83 s, sys: 281 ms, total: 2.12 s\n",
            "Wall time: 1.45 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about batch processing?"
      ],
      "metadata": {
        "id": "DZeyQefQPwQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn text chunks into a single list\n",
        "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]"
      ],
      "metadata": {
        "id": "EtgsqlqXSQWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Embed all texts in batches\n",
        "text_chunk_embeddings = embedding_model.encode(text_chunks,\n",
        "                                               batch_size=32, # you can use different batch sizes here for speed/performance, I found 32 works well for this use case\n",
        "                                               convert_to_tensor=True) # optional to return embeddings as tensor instead of array\n",
        "\n",
        "text_chunk_embeddings"
      ],
      "metadata": {
        "id": "9JoWiKNOSTq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd576876-ce9b-4452-f103-e47a198d9aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 465 ms, sys: 7.39 ms, total: 472 ms\n",
            "Wall time: 395 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0071, -0.0755, -0.0205,  ...,  0.0258, -0.0396,  0.0141],\n",
              "        [ 0.0259, -0.0702, -0.0171,  ...,  0.0283, -0.0479, -0.0148],\n",
              "        [ 0.0564, -0.0397, -0.0207,  ...,  0.0192, -0.0396, -0.0039],\n",
              "        ...,\n",
              "        [ 0.0109,  0.0319, -0.0289,  ...,  0.0763,  0.0237, -0.0272],\n",
              "        [ 0.0297, -0.0098, -0.0201,  ...,  0.0699,  0.0285, -0.0238],\n",
              "        [ 0.0270, -0.0286,  0.0103,  ...,  0.0457, -0.0323, -0.0239]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save embeddings to file**\n"
      ],
      "metadata": {
        "id": "9WDb5a0zSZJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embeddings to file\n",
        "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
        "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
        "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
      ],
      "metadata": {
        "id": "8S1NoMWUScy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import saved file and view\n",
        "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
        "text_chunks_and_embedding_df_load.head()"
      ],
      "metadata": {
        "id": "zjb36Y7cSlpT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8ca401f7-a4bd-41a5-fa31-a5cb07550189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   page_number                                     sentence_chunk  \\\n",
              "0          NaN  [fudging from] the complexity of the material ...   \n",
              "1          NaN  You do not \\r need to write full sentences or ...   \n",
              "2          NaN  49 \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\...   \n",
              "3          NaN  1 For Question 4, which word/s in the passage ...   \n",
              "4          NaN  50 \\r \\r \\r \\r \\r \\r \\r \\r \\r Reading skills \\...   \n",
              "\n",
              "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
              "0              1381               293             345.25   \n",
              "1              1113               220             278.25   \n",
              "2               722               153             180.50   \n",
              "3              1628               302             407.00   \n",
              "4               993               204             248.25   \n",
              "\n",
              "                                           embedding  \n",
              "0  [ 7.10453186e-03 -7.55081177e-02 -2.05419790e-...  \n",
              "1  [ 2.58541796e-02 -7.01962784e-02 -1.70616377e-...  \n",
              "2  [ 5.64004555e-02 -3.96810472e-02 -2.07439456e-...  \n",
              "3  [ 6.36236519e-02 -6.75108954e-02 -3.08494326e-...  \n",
              "4  [-1.61707476e-02 -7.01474622e-02 -4.12495732e-...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29b342b3-6ee8-4d94-aa15-4cb190625f69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>sentence_chunk</th>\n",
              "      <th>chunk_char_count</th>\n",
              "      <th>chunk_word_count</th>\n",
              "      <th>chunk_token_count</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[fudging from] the complexity of the material ...</td>\n",
              "      <td>1381</td>\n",
              "      <td>293</td>\n",
              "      <td>345.25</td>\n",
              "      <td>[ 7.10453186e-03 -7.55081177e-02 -2.05419790e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>You do not \\r need to write full sentences or ...</td>\n",
              "      <td>1113</td>\n",
              "      <td>220</td>\n",
              "      <td>278.25</td>\n",
              "      <td>[ 2.58541796e-02 -7.01962784e-02 -1.70616377e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>49 \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\...</td>\n",
              "      <td>722</td>\n",
              "      <td>153</td>\n",
              "      <td>180.50</td>\n",
              "      <td>[ 5.64004555e-02 -3.96810472e-02 -2.07439456e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1 For Question 4, which word/s in the passage ...</td>\n",
              "      <td>1628</td>\n",
              "      <td>302</td>\n",
              "      <td>407.00</td>\n",
              "      <td>[ 6.36236519e-02 -6.75108954e-02 -3.08494326e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>50 \\r \\r \\r \\r \\r \\r \\r \\r \\r Reading skills \\...</td>\n",
              "      <td>993</td>\n",
              "      <td>204</td>\n",
              "      <td>248.25</td>\n",
              "      <td>[-1.61707476e-02 -7.01474622e-02 -4.12495732e-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29b342b3-6ee8-4d94-aa15-4cb190625f69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29b342b3-6ee8-4d94-aa15-4cb190625f69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29b342b3-6ee8-4d94-aa15-4cb190625f69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-beff19e6-9214-4f0e-a65c-4414c20d0dbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-beff19e6-9214-4f0e-a65c-4414c20d0dbe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-beff19e6-9214-4f0e-a65c-4414c20d0dbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "text_chunks_and_embedding_df_load",
              "summary": "{\n  \"name\": \"text_chunks_and_embedding_df_load\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 430,\n        \"min\": 706,\n        \"max\": 2346,\n        \"num_unique_values\": 29,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84,\n        \"min\": 143,\n        \"max\": 438,\n        \"num_unique_values\": 30,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.63362585081441,\n        \"min\": 176.5,\n        \"max\": 586.5,\n        \"num_unique_values\": 29,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Chunking and embedding questions**"
      ],
      "metadata": {
        "id": "A7tbXnX2SyCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Import texts and embedding df\n",
        "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
        "\n",
        "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
        "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
        "\n",
        "# Convert texts and embedding df to list of dicts\n",
        "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
        "\n",
        "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
        "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "FiBedaGfSxUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19192924-0a65-44a8-9124-fd7ca04e3097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Similarity search**"
      ],
      "metadata": {
        "id": "CtE9vfe7TKD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks_and_embedding_df.head()"
      ],
      "metadata": {
        "id": "pzha232US7hL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4e75df81-a83c-426b-b44a-836af4b0474b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   page_number                                     sentence_chunk  \\\n",
              "0          NaN  [fudging from] the complexity of the material ...   \n",
              "1          NaN  You do not \\r need to write full sentences or ...   \n",
              "2          NaN  49 \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\...   \n",
              "3          NaN  1 For Question 4, which word/s in the passage ...   \n",
              "4          NaN  50 \\r \\r \\r \\r \\r \\r \\r \\r \\r Reading skills \\...   \n",
              "\n",
              "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
              "0              1381               293             345.25   \n",
              "1              1113               220             278.25   \n",
              "2               722               153             180.50   \n",
              "3              1628               302             407.00   \n",
              "4               993               204             248.25   \n",
              "\n",
              "                                           embedding  \n",
              "0  [0.00710453186, -0.0755081177, -0.020541979, 0...  \n",
              "1  [0.0258541796, -0.0701962784, -0.0170616377, 0...  \n",
              "2  [0.0564004555, -0.0396810472, -0.0207439456, 0...  \n",
              "3  [0.0636236519, -0.0675108954, -0.0308494326, 0...  \n",
              "4  [-0.0161707476, -0.0701474622, -0.0412495732, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fb14056-bd59-4a9a-8882-5c9aab47e397\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>page_number</th>\n",
              "      <th>sentence_chunk</th>\n",
              "      <th>chunk_char_count</th>\n",
              "      <th>chunk_word_count</th>\n",
              "      <th>chunk_token_count</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[fudging from] the complexity of the material ...</td>\n",
              "      <td>1381</td>\n",
              "      <td>293</td>\n",
              "      <td>345.25</td>\n",
              "      <td>[0.00710453186, -0.0755081177, -0.020541979, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>You do not \\r need to write full sentences or ...</td>\n",
              "      <td>1113</td>\n",
              "      <td>220</td>\n",
              "      <td>278.25</td>\n",
              "      <td>[0.0258541796, -0.0701962784, -0.0170616377, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>49 \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\r \\...</td>\n",
              "      <td>722</td>\n",
              "      <td>153</td>\n",
              "      <td>180.50</td>\n",
              "      <td>[0.0564004555, -0.0396810472, -0.0207439456, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1 For Question 4, which word/s in the passage ...</td>\n",
              "      <td>1628</td>\n",
              "      <td>302</td>\n",
              "      <td>407.00</td>\n",
              "      <td>[0.0636236519, -0.0675108954, -0.0308494326, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>50 \\r \\r \\r \\r \\r \\r \\r \\r \\r Reading skills \\...</td>\n",
              "      <td>993</td>\n",
              "      <td>204</td>\n",
              "      <td>248.25</td>\n",
              "      <td>[-0.0161707476, -0.0701474622, -0.0412495732, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fb14056-bd59-4a9a-8882-5c9aab47e397')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fb14056-bd59-4a9a-8882-5c9aab47e397 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fb14056-bd59-4a9a-8882-5c9aab47e397');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a43fffe4-8a38-46af-aa57-a6eddb051564\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a43fffe4-8a38-46af-aa57-a6eddb051564')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a43fffe4-8a38-46af-aa57-a6eddb051564 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "text_chunks_and_embedding_df",
              "summary": "{\n  \"name\": \"text_chunks_and_embedding_df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 430,\n        \"min\": 706,\n        \"max\": 2346,\n        \"num_unique_values\": 29,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 84,\n        \"min\": 143,\n        \"max\": 438,\n        \"num_unique_values\": 30,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chunk_token_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 107.63362585081441,\n        \"min\": 176.5,\n        \"max\": 586.5,\n        \"num_unique_values\": 29,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "N5evWiQKS92L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612663b7-7ba7-4c36-fd70-6f3c78bd6db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 7.1045e-03, -7.5508e-02, -2.0542e-02,  5.3325e-02, -7.2728e-02,\n",
              "        -2.5395e-02,  1.0261e-02,  5.3646e-02, -1.3570e-02,  4.7879e-03,\n",
              "         6.0068e-02, -1.1683e-02,  8.1880e-02,  1.5494e-02, -4.0406e-02,\n",
              "        -1.0858e-02,  4.4307e-02, -2.1993e-02, -2.7438e-02,  2.4333e-02,\n",
              "        -2.9353e-02,  2.8078e-02, -8.1387e-03, -5.5367e-02, -2.4519e-02,\n",
              "         1.2610e-02, -3.0707e-02, -3.1068e-02,  1.2954e-02, -6.4856e-02,\n",
              "        -1.5680e-02,  3.6647e-02, -3.9773e-02, -1.8977e-02,  2.2121e-06,\n",
              "        -5.6490e-02, -2.3480e-02,  1.3385e-02, -5.0297e-02,  2.9676e-02,\n",
              "         7.0152e-02,  5.9260e-02,  4.5085e-02, -9.0790e-03, -2.8074e-03,\n",
              "         4.1529e-03,  2.0545e-02,  5.0574e-02,  3.6151e-02,  1.8902e-02,\n",
              "         1.0677e-02, -1.4560e-02,  4.3371e-02, -1.5906e-02,  9.5423e-02,\n",
              "         9.4999e-03,  6.2746e-03,  1.3461e-02,  5.6207e-02,  1.2438e-01,\n",
              "        -2.8209e-02,  3.6967e-02, -1.4678e-02,  1.2529e-02,  1.0953e-02,\n",
              "        -1.3343e-02,  3.8065e-02, -8.5211e-02,  5.8674e-02, -6.2003e-03,\n",
              "         6.8381e-02,  2.2296e-02, -3.8713e-02, -8.7479e-03, -7.0381e-02,\n",
              "         2.0222e-02,  9.9543e-03,  4.0532e-03, -1.3615e-02, -5.5223e-02,\n",
              "         3.4723e-02,  3.5883e-02, -2.5394e-02,  1.5825e-02,  5.8257e-04,\n",
              "         8.2041e-03,  1.9152e-02, -2.3958e-02,  3.5345e-02, -3.6278e-02,\n",
              "         2.7031e-02, -2.1671e-02, -5.5434e-02,  7.9264e-02, -7.2501e-03,\n",
              "        -6.6863e-03,  6.2511e-04, -1.5444e-02,  4.5729e-02, -9.2402e-03,\n",
              "        -1.8899e-02,  7.3955e-03,  8.8647e-03,  6.7184e-02,  2.5188e-02,\n",
              "        -1.2559e-02,  9.1851e-02, -1.5305e-02, -5.3264e-02,  2.5957e-02,\n",
              "         8.5528e-03, -5.7634e-02, -7.9536e-02, -2.6019e-02,  2.7346e-02,\n",
              "        -3.5625e-02, -2.4101e-03, -9.6169e-02,  2.1487e-02, -4.9146e-02,\n",
              "        -3.3509e-02, -1.6647e-02, -5.1050e-03, -1.8992e-02,  2.0783e-02,\n",
              "        -1.5741e-02, -3.2570e-02, -3.9937e-04, -6.9465e-03, -7.0223e-02,\n",
              "         1.1474e-02,  1.4554e-02,  4.9174e-02, -1.8683e-02,  6.7901e-03,\n",
              "         1.3234e-02,  1.8413e-02, -1.5347e-02, -5.0877e-02, -1.8027e-02,\n",
              "         2.1614e-02, -2.8581e-02,  2.1583e-02,  6.5867e-03,  2.4762e-02,\n",
              "         9.6306e-03, -5.9107e-03, -1.7295e-02,  2.0269e-02,  2.9720e-02,\n",
              "        -1.7571e-02,  7.0978e-02, -4.9024e-02, -2.4281e-02,  2.4518e-02,\n",
              "         1.9364e-02,  7.1247e-02,  1.9823e-02,  6.1527e-02,  2.5222e-02,\n",
              "         2.9720e-02, -6.0668e-03,  3.6097e-02, -1.2933e-02, -2.1147e-03,\n",
              "         5.2052e-02,  7.6149e-03, -1.2132e-02,  4.3789e-03,  3.5870e-02,\n",
              "        -6.2269e-03,  4.2782e-02,  5.8332e-03,  3.8420e-02,  4.9043e-02,\n",
              "         9.7184e-02,  7.4902e-03,  3.6238e-02, -2.0625e-02,  5.6453e-02,\n",
              "         4.7177e-02, -3.1105e-02,  1.6973e-02,  9.1624e-03,  1.5546e-02,\n",
              "         8.4682e-03,  4.8225e-02, -1.1776e-02, -2.1327e-03, -3.8708e-02,\n",
              "        -4.7821e-02,  4.9506e-02,  2.2405e-02, -2.8300e-02,  4.3537e-03,\n",
              "         2.5175e-02,  5.3032e-03, -2.8653e-02, -1.8072e-02, -2.4594e-02,\n",
              "         5.9062e-02,  4.8949e-02,  6.8031e-02,  2.3883e-02,  3.8825e-02,\n",
              "        -9.8401e-03,  8.7934e-02, -9.5269e-03, -1.2335e-02,  6.6819e-02,\n",
              "        -2.5994e-03,  8.3416e-04, -1.7913e-02, -4.4714e-02, -1.0874e-03,\n",
              "        -1.3372e-02, -1.2211e-02, -4.8709e-02, -3.3205e-02,  8.5710e-03,\n",
              "        -2.4248e-03, -1.3292e-02, -3.5291e-02,  3.5080e-02, -1.7307e-02,\n",
              "        -9.3230e-02, -4.5350e-02, -1.8967e-02, -3.2938e-02, -2.7870e-02,\n",
              "        -1.2339e-02,  4.0420e-02,  7.7736e-03,  2.5361e-02, -5.2330e-02,\n",
              "        -5.7196e-02,  4.4656e-02,  8.7197e-02,  2.5046e-02, -4.2035e-02,\n",
              "         1.5775e-02, -1.5000e-02,  5.2296e-02,  2.0094e-03, -4.2406e-02,\n",
              "        -8.2428e-02,  2.6143e-02,  3.1033e-02,  2.4748e-02,  1.3196e-02,\n",
              "        -3.7968e-03, -3.3077e-02, -3.9199e-03,  1.1554e-02,  6.9702e-02,\n",
              "        -6.2521e-02, -6.5115e-02,  2.3699e-02, -2.1907e-04,  3.7013e-02,\n",
              "        -8.5776e-03, -1.9824e-02, -2.7338e-02,  3.4780e-03,  3.7633e-02,\n",
              "        -1.8154e-02, -2.0115e-02, -3.8639e-02, -5.0045e-02, -2.3583e-03,\n",
              "        -1.5271e-02,  1.3889e-02, -1.3809e-03,  7.9772e-03,  3.1732e-02,\n",
              "         1.0627e-02,  1.3887e-02,  2.5958e-02,  4.5509e-02,  3.0366e-02,\n",
              "        -5.2060e-03, -4.8609e-03, -1.3746e-02, -3.9237e-03, -8.1726e-03,\n",
              "         7.3399e-02,  7.0162e-02, -1.2607e-01, -2.4398e-02,  1.2400e-02,\n",
              "         2.2195e-03, -3.2857e-02, -1.9358e-02, -1.4324e-02,  1.0905e-03,\n",
              "        -2.4532e-02,  4.7353e-02, -2.0453e-02,  4.9045e-02,  4.1325e-02,\n",
              "        -1.5203e-02, -4.0781e-02,  8.2528e-03, -2.8079e-02,  3.2134e-02,\n",
              "         5.6981e-02,  7.1645e-02, -7.3683e-02, -1.4778e-02, -2.3099e-02,\n",
              "         1.8692e-02,  2.5136e-03,  3.0383e-02,  7.8485e-02, -3.9803e-02,\n",
              "         6.7125e-03, -4.3552e-02, -3.5991e-02,  1.3400e-03,  2.8688e-02,\n",
              "        -1.9311e-02, -3.5118e-02, -2.2860e-02, -1.5432e-02, -1.4102e-02,\n",
              "        -1.1626e-01,  3.3998e-02,  4.2896e-02,  6.8153e-02, -1.4001e-02,\n",
              "         1.8231e-02,  2.2662e-02, -1.0695e-03, -1.9344e-02, -1.1609e-02,\n",
              "         3.4453e-03, -2.6954e-02, -5.2975e-02, -4.4343e-02,  2.5402e-02,\n",
              "        -3.6660e-03, -1.2382e-02, -1.0478e-02, -3.0517e-02,  3.6779e-02,\n",
              "         3.0143e-02,  5.2066e-02, -2.9318e-02,  5.7292e-03,  5.0193e-03,\n",
              "         9.5200e-02, -1.7023e-02, -4.2554e-02,  3.3332e-04, -1.4646e-02,\n",
              "         6.6696e-02,  4.5700e-02,  1.3073e-02,  4.7638e-02, -2.7621e-02,\n",
              "        -5.5924e-03,  8.3389e-04, -3.9021e-02,  3.0883e-02,  6.0704e-02,\n",
              "         8.7054e-03,  1.7754e-02, -4.2443e-02, -3.9354e-02,  3.6116e-02,\n",
              "         1.7405e-02, -4.8231e-02, -4.6342e-02,  2.8747e-02,  1.8563e-02,\n",
              "         5.3952e-03, -9.4288e-03, -6.4224e-02, -9.7514e-02, -1.6280e-02,\n",
              "         2.9638e-02, -4.9332e-02,  6.6435e-02, -1.9205e-02, -3.2117e-02,\n",
              "         4.4456e-02, -3.5187e-03, -4.7194e-02, -6.6102e-02, -1.0829e-02,\n",
              "         2.3516e-02, -9.3989e-02, -6.9549e-02, -3.6976e-02, -2.9418e-02,\n",
              "         3.6813e-02, -2.9448e-02,  5.3092e-03,  1.9594e-02,  2.8233e-02,\n",
              "         6.5494e-03,  7.6476e-03,  3.8724e-02, -2.2880e-02,  1.1294e-02,\n",
              "         6.4599e-03,  2.7314e-02, -1.4801e-02, -4.3480e-02, -3.5539e-02,\n",
              "         6.8658e-02, -7.2723e-02, -2.5697e-02, -1.2261e-02,  6.0786e-02,\n",
              "         3.5526e-02,  1.3307e-02, -5.0980e-03, -3.7790e-04, -3.4660e-02,\n",
              "        -5.4598e-02,  2.5181e-02,  3.0851e-02, -2.5505e-02,  2.2698e-02,\n",
              "         1.7498e-02,  4.4549e-02,  5.9737e-02, -2.6489e-02,  2.4480e-02,\n",
              "         1.2777e-02, -3.0474e-02, -2.8938e-02,  3.6529e-02, -7.6522e-02,\n",
              "        -4.8429e-02, -1.5519e-03, -1.6587e-03,  9.7872e-03, -6.8913e-02,\n",
              "        -7.6404e-02,  4.0023e-02,  1.1025e-01,  4.7408e-02,  6.3296e-03,\n",
              "         3.4469e-02,  1.9486e-02, -1.2516e-02,  2.8211e-02,  4.2334e-03,\n",
              "         4.1258e-02, -1.4104e-02, -2.2398e-02,  2.9331e-02, -8.2957e-03,\n",
              "         8.3190e-03,  1.0101e-02, -3.2732e-02, -3.9759e-02,  5.6426e-02,\n",
              "         5.5119e-02,  5.1013e-02, -6.1302e-02, -2.9076e-02, -3.3954e-02,\n",
              "         1.6179e-02, -4.7456e-02, -2.7025e-02, -3.1734e-03, -6.0706e-02,\n",
              "         8.0934e-03,  1.7703e-02, -2.8613e-02,  1.6985e-02,  1.5415e-02,\n",
              "         1.6979e-02, -1.4737e-02, -6.1311e-02, -2.7703e-02, -1.0256e-02,\n",
              "         3.2468e-02, -2.5445e-02, -4.6767e-02,  8.1186e-03,  5.0121e-03,\n",
              "        -3.7196e-02,  1.2389e-02, -4.9834e-02,  3.1085e-02, -1.3098e-02,\n",
              "        -3.3004e-02, -2.1381e-02, -3.6950e-02,  2.0247e-02,  5.7288e-03,\n",
              "         6.1561e-03,  2.9010e-02, -2.1133e-02,  5.5917e-02,  2.0194e-02,\n",
              "        -7.3191e-03,  3.5191e-03, -3.2796e-02,  6.0914e-03, -6.1618e-02,\n",
              "         6.2010e-02,  3.7936e-02,  5.4529e-02,  8.9189e-06,  1.6647e-02,\n",
              "        -4.1890e-02, -2.8098e-02,  2.1526e-02, -6.0089e-02, -5.8646e-02,\n",
              "         1.6282e-02, -3.7830e-02, -1.1770e-02, -5.1392e-02,  2.5204e-02,\n",
              "         7.4962e-03, -1.0947e-02,  1.6536e-02, -4.5266e-02,  1.1822e-02,\n",
              "         7.7929e-03,  4.4172e-02,  9.2883e-03, -5.9934e-02,  3.5632e-02,\n",
              "        -3.0594e-02, -2.6610e-02,  1.6347e-02,  1.9476e-02, -1.9111e-02,\n",
              "         1.7951e-03, -2.2159e-02,  4.1887e-02,  3.1827e-02,  1.8369e-02,\n",
              "        -1.2799e-02, -3.7033e-02,  5.9965e-02,  2.5172e-02,  4.5559e-02,\n",
              "         1.0188e-02, -2.6937e-02,  2.3164e-02, -1.4305e-03, -1.4615e-02,\n",
              "        -5.1646e-03,  1.7787e-02, -6.2413e-02,  1.4078e-02, -3.3864e-02,\n",
              "        -6.1307e-33, -5.9262e-02, -6.5584e-02,  5.6872e-02,  1.1708e-02,\n",
              "        -3.8686e-03, -1.9578e-02, -2.8720e-02,  7.0141e-03, -4.1978e-03,\n",
              "         1.1155e-02,  8.5482e-03, -4.6404e-02,  1.8218e-02, -1.6430e-03,\n",
              "         2.2593e-02,  2.1669e-02, -1.6762e-02,  1.1294e-02, -6.7436e-02,\n",
              "        -4.0407e-02,  2.5091e-02,  9.9398e-04,  1.8812e-02, -1.4494e-02,\n",
              "         7.0833e-02, -4.6996e-02,  4.8730e-03, -1.9465e-02, -5.4958e-03,\n",
              "         1.6310e-02, -1.8492e-02, -6.3708e-03,  3.9843e-02,  3.1431e-03,\n",
              "         6.9097e-04,  3.6543e-02, -7.6142e-02, -7.4231e-02,  1.1192e-02,\n",
              "         6.0545e-02, -1.9260e-02, -3.3100e-02, -6.3444e-03, -2.1901e-02,\n",
              "         4.7353e-02, -2.4632e-02,  3.4649e-02, -1.1232e-03, -3.2719e-02,\n",
              "        -1.9405e-02, -5.6155e-02, -1.2300e-02,  2.8214e-02,  8.1655e-03,\n",
              "        -5.3159e-02,  3.0918e-02, -2.4186e-03, -7.6198e-02, -5.3147e-02,\n",
              "         3.9137e-02,  5.7027e-02,  4.4361e-02, -1.8079e-02,  6.0229e-02,\n",
              "        -3.9037e-02,  3.0577e-02, -2.3594e-02, -1.9550e-02,  8.3723e-03,\n",
              "        -2.3543e-02, -7.3094e-03,  3.1589e-03,  8.2815e-02,  3.5282e-02,\n",
              "         3.3704e-02,  1.1747e-02,  1.2756e-02,  2.5765e-02,  4.0937e-02,\n",
              "         5.0564e-03, -8.0417e-03, -1.5988e-02, -1.6725e-02, -3.7662e-02,\n",
              "        -3.6706e-02,  2.1484e-02, -1.4434e-02,  3.9019e-02,  4.0175e-02,\n",
              "        -1.8148e-02, -4.3966e-03,  4.9588e-03, -7.5320e-03,  3.6023e-03,\n",
              "         2.9676e-03,  7.7452e-03,  4.0791e-03,  3.4397e-02, -2.0293e-02,\n",
              "         6.8483e-03, -4.6243e-05, -1.0448e-02,  4.9214e-03, -4.7439e-03,\n",
              "         9.5582e-03,  1.5625e-02, -6.8059e-02,  1.2528e-02, -7.3189e-02,\n",
              "        -3.3360e-02,  1.5176e-02, -3.5799e-02,  4.4351e-02, -3.0518e-02,\n",
              "        -1.0922e-03, -2.7016e-02, -3.6780e-04, -2.4625e-02, -3.0800e-02,\n",
              "        -6.1389e-03,  6.2595e-02, -2.8497e-02, -2.2691e-02, -1.2045e-02,\n",
              "         6.0969e-03,  4.6560e-03,  1.2549e-02, -4.5530e-02, -2.4438e-02,\n",
              "         2.0517e-02,  2.0188e-02,  4.0540e-02,  3.0201e-07,  2.9606e-02,\n",
              "         4.8747e-02,  2.1314e-02,  1.5640e-02, -2.2433e-04, -3.5506e-02,\n",
              "        -1.3779e-02, -1.7297e-02, -4.3783e-02,  4.1732e-03,  3.7652e-02,\n",
              "         9.9341e-03,  1.7194e-02,  2.6038e-02, -3.3048e-02, -5.9646e-02,\n",
              "         2.8445e-02, -7.8668e-03, -4.4220e-02, -2.5511e-02, -8.9792e-03,\n",
              "         2.1402e-02, -3.1000e-02,  1.0440e-02, -2.5428e-02, -7.8969e-02,\n",
              "         8.8211e-04, -4.2219e-02,  1.5763e-02,  2.5020e-02,  2.8394e-02,\n",
              "        -7.3792e-02,  1.4286e-02,  4.3382e-02, -1.8133e-02, -2.7275e-02,\n",
              "         6.6768e-02,  9.1500e-03,  1.0025e-02,  9.2110e-02, -2.2920e-02,\n",
              "        -2.6559e-02, -2.8073e-03, -1.9081e-02,  1.7387e-02,  5.0342e-02,\n",
              "         2.0652e-02, -2.9815e-02, -4.8842e-02, -1.9409e-02,  2.2262e-02,\n",
              "         2.2096e-02, -2.5461e-02, -5.4357e-03,  3.2770e-02, -2.9632e-02,\n",
              "         3.0422e-02, -5.7260e-03,  4.6420e-02,  4.3196e-02, -4.5722e-02,\n",
              "        -3.9448e-02, -1.4465e-02, -2.2887e-02,  3.7283e-02, -4.8893e-02,\n",
              "        -2.4695e-02,  3.0004e-34,  7.0857e-03, -6.1655e-02, -1.9485e-02,\n",
              "        -1.6543e-02,  3.6255e-03, -1.1541e-02,  4.2811e-02,  6.1201e-03,\n",
              "         2.5836e-02, -3.9588e-02,  1.4090e-02], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Time to perform a semantic search**"
      ],
      "metadata": {
        "id": "rwyGS5KtS8HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util, SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                      device=device) # choose the device to load the model to"
      ],
      "metadata": {
        "id": "C1x2csCUTdvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the query\n",
        "# Note: This could be anything. But since we're working with a nutrition textbook, we'll stick with nutrition-based queries.\n",
        "query = \"reading skill\"\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# 2. Embed the query to the same numerical space as the text examples\n",
        "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
        "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "# 3. Get similarity scores with the dot product (we'll time this for fun)\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "# 4. Get the top-k results (we'll keep this to 5)\n",
        "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
        "top_results_dot_product"
      ],
      "metadata": {
        "id": "BkflXgdnToeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbdffebe-66f1-4ce3-ad18-457ec2d56aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: reading skill\n",
            "Time take to get scores on 30 embeddings: 0.00833 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([0.5677, 0.5357, 0.5271, 0.5006, 0.4489], device='cuda:0'),\n",
              "indices=tensor([23,  2,  4, 17,  5], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define helper function to print wrapped text\n",
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length=80):\n",
        "    wrapped_text = textwrap.fill(text, wrap_length)\n",
        "    print(wrapped_text)"
      ],
      "metadata": {
        "id": "LTeBbEWyTvda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the result!!"
      ],
      "metadata": {
        "id": "S_KxlFP8VO_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query: '{query}'\\n\")\n",
        "print(\"Results:\")\n",
        "# Loop through zipped together scores and indicies from torch.topk\n",
        "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
        "    print(f\"Score: {score:.4f}\")\n",
        "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "    print(\"Text:\")\n",
        "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "    # Print the page number too so we can reference the textbook further (and check the results)\n",
        "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "gZYJbuqQUVmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3e2646-a753-46db-de0a-06a93b2c2219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: 'reading skill'\n",
            "\n",
            "Results:\n",
            "Score: 0.5677\n",
            "Text:\n",
            "61                                       Reading skills       2.2 Look at tliis\n",
            "task based on (he Reading passage. For each     question, underline the type of\n",
            "information you need to scan Tor.   The first two have been done for you.\n",
            "Which paragraph contains the following information?     N. B You may use any\n",
            "letter more than once     Write the correct letter. A-E, next to questions 1-7\n",
            "below,     1 visual evidence of the gecko's ability to resist water     2 a\n",
            "question that is yet to be answered by the researchers     3 the method used to\n",
            "calculate the gripping power of geckos     4 the researcher's opinion of the\n",
            "gecko’s gripping ability     5 a mention of the different environments where\n",
            "geckos can be found     6 the contrast between Stark's research and the work of\n",
            "other researchers     7 the definition of a scientific term       2.3 It is\n",
            "important to fully understand what you are looking for in   the passage. Answer\n",
            "these questions, based on Question I in the   task above,     1 Which of the\n",
            "following do you think is 'visual evidence’?     A som et hing the re sea re he\n",
            "rs belie ve   B something the researchers have seen   C something the\n",
            "researchers have read about     2 Which of the following means the same as\n",
            "'ability to resist   water'?     A soaks up water   B sinks in water   C stops\n",
            "water getting in     3 Scan the passage to find 'visual evidence' of an ability\n",
            "to resist   water, which paragraph contains this information?     2.4 Study\n",
            "Questions 2-7 in 2.2 carefully and match them to   paragraphs A-E. Remember, the\n",
            "questions are not in the same   order as the passage.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.5357\n",
            "Text:\n",
            "49                                                   Reading skills       2.2\n",
            "Look at the remaining questions, 4-6, Underline the words that   will help you\n",
            "locale the information in the passage and highlight   the details you need to\n",
            "find. Then answer the questions.     4 What did the ancient people use to keep\n",
            "their ochre mixture in?     5 Nowadays, who makes use of ochre?     6 Apart from\n",
            "painting, what else might ancient humans have used ochre for?       3\n",
            "Notes/flow-chart/diagram completion     The questions in 3.] all focus on\n",
            "paraphrase. Paraphrase is the use of   different words with the same meaning.\n",
            "This helps to test how much   of the Reading passage you understand.     3.1\n",
            "Look again at Questions 4-6.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.5271\n",
            "Text:\n",
            "50                   Reading skills       3.3 Look at the sentence completion\n",
            "task below. Find words in the   passage in 3.2 that are paraphrases of the\n",
            "underlined words.       Choose NO MORE THAN THREE WORDS from the passage for\n",
            "each answer.     1 Two ingredients used to make paint found in the cave were\n",
            ".....and......     2 Two examples of to£i§ used to make the paint that were\n",
            "found in the cave     are...and...       3 The scientists used the.     QUt how\n",
            "the paint was made       .... on the equipment to help work       3.4 Carefully\n",
            "read the text, before and after the words you have   found. Then complete\n",
            "Questions 1-3.     Flow-chart and Note completion tasks     A flow chart is a\n",
            "diagram iliai shows ilie sequence of events in a   process. In flow-chart\n",
            "completion questions, the information may   not be presented in the same order\n",
            "as in the passage.     3.5 Study the flow-chart completion task below. For\n",
            "Questions 1-6,   decide what type of information you need to find.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.5006\n",
            "Text:\n",
            "3.3 Read statements 4-8, then underline ihc relevant parts in the text. Arc the\n",
            "statements True, False or Nci Given?     4 Atiania has experienced more dramatic\n",
            "weather change than other areas of the US.     5 Roofs that are dark in colour\n",
            "help address the issue of Urban Heat islands.     6 Singapore's Supenrees are\n",
            "made entirely from natural materials.     7 The designers of the Supertrees\n",
            "originally planned to plant very tall trees.     8 The Superirees require\n",
            "regular maintenance.       3.4 Read statements 1-8 again and correct any that\n",
            "were false.       58\n",
            "information     In this unit you will practise:     • identifying types of\n",
            "information     • locating and matching information     • connecting ideas     •\n",
            "matching sentence endings     • matching information     v**' vv w E1- + 'f m\n",
            "t Identifying types of information     For matching information tasks, you need\n",
            "to locate ail idea or piece of   information in the texi and match it to a\n",
            "phrase that accurately describes it.       1.1 Read the extracts from two\n",
            "separate paragraphs of a Reading   passage.\n",
            "Page number: nan\n",
            "\n",
            "\n",
            "Score: 0.4489\n",
            "Text:\n",
            "1 neon - ,Sant £ flirty tlinf is created fiij jchnf     Choose ONE WORD ONLY\n",
            "from th$ passage for each answer.     How pigment was made in ancient times\n",
            "Test Tip Make sure   you read the whole   passage so that you can   locate any\n",
            "key words   and paraphrases from   the questions. Take   highlighter pens into\n",
            "the exam with you. Use   a different colour for   each task, to highlight\n",
            "important parts of the   text This will help save   time when checking   I\n",
            "answers,         51\n",
            "Reading skills       3.6 Look ai the two Reading passages in i.l and 3,2. Which\n",
            "words   or ideas are paraphrases of the underlined words in the flow   chart?\n",
            "Highlight the pans you need u> read in detail.     3.7 Carefully read the\n",
            "passages in I.l and 3.2 and complete the flow   chart. Make sure you use ONE\n",
            "WORD ONLV from the passages.     Note completion tasks are similar to flow-chart\n",
            "completion, but may   cover a larger pan of the Reading passage. Again, the\n",
            "Information may   not he presented in the same order as the information in the\n",
            "passage.\n",
            "Page number: nan\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functionizing our semantic search pipeline"
      ],
      "metadata": {
        "id": "HPsipGs2VDP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                model: SentenceTransformer=embedding_model,\n",
        "                                n_resources_to_return: int=5,\n",
        "                                print_time: bool=True):\n",
        "    \"\"\"\n",
        "    Embeds a query with model and returns top k scores and indices from embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = model.encode(query,\n",
        "                                   convert_to_tensor=True)\n",
        "\n",
        "    # Get dot product scores on embeddings\n",
        "    start_time = timer()\n",
        "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "    end_time = timer()\n",
        "\n",
        "    if print_time:\n",
        "        print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "    scores, indices = torch.topk(input=dot_scores,\n",
        "                                 k=n_resources_to_return)\n",
        "\n",
        "    return scores, indices\n",
        "\n",
        "def print_top_results_and_scores(query: str,\n",
        "                                 embeddings: torch.tensor,\n",
        "                                 pages_and_chunks: list[dict]=pages_and_chunks,\n",
        "                                 n_resources_to_return: int=5):\n",
        "    \"\"\"\n",
        "    Takes a query, retrieves most relevant resources and prints them out in descending order.\n",
        "\n",
        "    Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
        "    \"\"\"\n",
        "\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings,\n",
        "                                                  n_resources_to_return=n_resources_to_return)\n",
        "\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    print(\"Results:\")\n",
        "    # Loop through zipped together scores and indicies\n",
        "    for score, index in zip(scores, indices):\n",
        "        print(f\"Score: {score:.4f}\")\n",
        "        # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "        print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "        # Print the page number too so we can reference the textbook further and check the results\n",
        "        print(f\"Page number: {pages_and_chunks[index]['page_number']}\")\n",
        "        print(\"\\n\")"
      ],
      "metadata": {
        "id": "1E9TveJnVCFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"listerning skills\"\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "id": "bxdP6qeXVFDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5837e7b-37ae-4502-d87d-c57bb2b9903f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Time taken to get scores on 30 embeddings: 0.00007 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.3542, 0.3339, 0.3295, 0.2792, 0.2771], device='cuda:0'),\n",
              " tensor([ 4, 23,  2,  0,  5], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Loading the LLM**"
      ],
      "metadata": {
        "id": "4xjBvWY1VhxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "CrvHhiP8V75t",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e4c43c-49a3-4f8b-97ef-7f6aaf25b9f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch<3,>=2.0->bitsandbytes) (79.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "fzmsWcT5ViGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "use_quantization_config = False\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "                                         bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "\n",
        "if (is_flash_attn_2_available()) and (torch.cuda.get_device_capability(0)[0] >= 8):\n",
        "  attn_implementation = \"flash_attention_2\"\n",
        "else:\n",
        "  attn_implementation = \"sdpa\"\n",
        "print(f\"[INFO] Using attention implementation: {attn_implementation}\")\n",
        "\n",
        "# 2. Pick a model we'd like to use (this will depend on how much GPU memory you have available)\n",
        "#model_id = \"google/gemma-7b-it\"\n",
        "model_id = model_id # (we already set this above)\n",
        "print(f\"[INFO] Using model_id: {model_id}\")\n",
        "\n",
        "# 3. Instantiate tokenizer (tokenizer turns text into numbers ready for the model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
        "\n",
        "# 4. Instantiate the model\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id,\n",
        "                                                 torch_dtype=torch.float16, # datatype to use, we want float16\n",
        "                                                 quantization_config=quantization_config if use_quantization_config else None,\n",
        "                                                 low_cpu_mem_usage=False, # use full memory\n",
        "                                                 attn_implementation=attn_implementation) # which attention version to use\n",
        "\n",
        "if not use_quantization_config: # quantization takes care of device setting automatically, so if it's not used, send model to GPU\n",
        "    llm_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "9rECNGZ-Vo1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "fa90bbe246da435894092b3a5158b56e",
            "766d9ec09be14714b714d23444c41a1b",
            "ccd8aba47cd84c13895a0c4b8572b930",
            "4b65f1a444fc44fc890e5fba6abff13f",
            "1e85630d2d9c4208bba52a53bbcded0e",
            "90928b6e1efa498b8e21375c91decd70",
            "09b6515af05e45cf9e9634f2a0119955",
            "df80b12d28a9442989c0436480b1d351",
            "6b3f0b0a58ad46dea3f035a7afadc1e8",
            "3b5178a1f8924cfbb3b5efe087406596",
            "b2fc4f673402410bb9159974b2dc3d2f"
          ]
        },
        "outputId": "9c646d9e-8955-4068-d08d-9b93799c7129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using attention implementation: sdpa\n",
            "[INFO] Using model_id: google/gemma-2b-it\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa90bbe246da435894092b3a5158b56e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got an LLM!\n",
        "\n",
        "Let's check it out."
      ],
      "metadata": {
        "id": "CqhKtmf_XHFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model"
      ],
      "metadata": {
        "id": "FDTz85LtXI6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba4d8d2-5bdd-4ee1-9e96-bfbf09d22f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GemmaForCausalLM(\n",
              "  (model): GemmaModel(\n",
              "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-17): 18 x GemmaDecoderLayer(\n",
              "        (self_attn): GemmaAttention(\n",
              "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
              "        )\n",
              "        (mlp): GemmaMLP(\n",
              "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
              "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
              "          (act_fn): GELUActivation()\n",
              "        )\n",
              "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
              "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
              "    (rotary_emb): GemmaRotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we get the number of parameters in our model?"
      ],
      "metadata": {
        "id": "JKcW3pu-XQe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num_params(model: torch.nn.Module):\n",
        "    return sum([param.numel() for param in model.parameters()])\n",
        "\n",
        "get_model_num_params(llm_model)"
      ],
      "metadata": {
        "id": "ZtUPHXoAXPzl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00ba5f7-ca8d-4f3f-c223-007e053f1010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2506172416"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Generating text with our LLM(gemma)**"
      ],
      "metadata": {
        "id": "-0pnXKNPXcMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"how can I improve speaking skills\"\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "# Create prompt template for instruction-tuned model\n",
        "dialogue_template = [\n",
        "    {\"role\": \"user\",\n",
        "     \"content\": input_text}\n",
        "]\n",
        "\n",
        "# Apply the chat template\n",
        "prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                       tokenize=False, # keep as raw text (not tokenized)\n",
        "                                       add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ],
      "metadata": {
        "id": "YUWT-ymiXgrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30729e77-08b0-4573-da6b-bd3e5fa300de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text:\n",
            "how can I improve speaking skills\n",
            "\n",
            "Prompt (formatted):\n",
            "<bos><start_of_turn>user\n",
            "how can I improve speaking skills<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Tokenize the input text (turn it into numbers) and send it to GPU\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "\n",
        "# Generate outputs passed on the tokenized input\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             max_new_tokens=256) # define the maximum number of new tokens to create\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ],
      "metadata": {
        "id": "cus2lrXWXpcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4194a5-857b-45f6-9f9e-e08619da2a11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input (tokenized):\n",
            "{'input_ids': tensor([[    2,     2,   106,  1645,   108,  1139,   798,   590,  4771, 13041,\n",
            "          7841,   107,   108,   106,  2516,   108]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "\n",
            "Model output (tokens):\n",
            "tensor([     2,      2,    106,   1645,    108,   1139,    798,    590,   4771,\n",
            "         13041,   7841,    107,    108,    106,   2516,    108,    688, 235274,\n",
            "        235265,  19670, 186522,  66058,    108, 235290, 100922,    575,  30893,\n",
            "           675,  11634,  22660,    689,   6016,    675,    476,   5255,   9670,\n",
            "        235265,    108, 235290,  20470,    476,   5255,  10036,   2778,    689,\n",
            "          3650,  16875, 235265,    108, 235290,  15940,   5804,  13041,    578,\n",
            "         10724,   1355,    577,  11441,   4516,    604,  13194, 235265,    109,\n",
            "           688, 235284, 235265,  26349,    611,  58212,  42535,  66058,    108,\n",
            "        235290,   8138,   6137,    577,    573,   9788,    576,    573,   5255,\n",
            "        235269,   3359, 187457, 235269,  36168, 235269,    578,   7512, 235265,\n",
            "           108, 235290,   5362,  74569,   8112,    578,  48363,    577,   3918,\n",
            "          5112,  74569, 235265,    108, 235290,  19670,  13041,   3907,    578,\n",
            "         35070,    921,  16129, 235269,  28643,    611,   2167,  65359, 235265,\n",
            "           109,    688, 235304, 235265,  77868,   3883,  84950,  66058,    108,\n",
            "        235290,   4814,  44224,    575,    573,   4408,   5255, 235269,   2145,\n",
            "         26922,    578,   2173, 235290,  44557, 235265,    108, 235290,  35170,\n",
            "           577,  76274, 235269, 231523, 235269,    578,   4296,    575,    573,\n",
            "          5255, 235265,    108, 235290,   5362, 168402,    578,  70090,  53304,\n",
            "         10423,    577,   3918,    888,   3907, 235265,    109,    688, 235310,\n",
            "        235265,   4814,  14495,   2752,  66058,    108, 235290,   7248,    675,\n",
            "          3069, 235303, 235256,   6142,    689,   3890,  26448,    578,  20914,\n",
            "          7695,    577,    978,   5766,   6205, 235265,    108, 235290,   8138,\n",
            "          6137,    577,  33342, 235269,  94152, 235269,    578,  13060,   5449,\n",
            "        235265,    108, 235290,   5362,    476,  25730,    578,    573, 118687,\n",
            "           577,   1717, 120352,    578,   4891,  36457, 235265,    109,    688,\n",
            "        235308, 235265,   5362,  20798, 113230,  66058,    108, 235290,   5362,\n",
            "        168402, 235269,  44816, 235269,    578,   1156,   9095,  43464,    577,\n",
            "          2676,    861,  22230,   5255, 235265,    108, 235290,  13466,  14554,\n",
            "           578,   5607,   4918,    675,  99013,    577,   4771,  61516,    578,\n",
            "         74569, 235265,    109,    688, 235318, 235265,  15940,    578,  73763,\n",
            "         66058,    108], device='cuda:0')\n",
            "\n",
            "CPU times: user 7.58 s, sys: 93.3 ms, total: 7.68 s\n",
            "Wall time: 7.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the output tokens to text\n",
        "outputs_decoded = tokenizer.decode(outputs[0])\n",
        "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
      ],
      "metadata": {
        "id": "CalUd3pcYMnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "242d8189-4720-476d-a836-8b49b8a068fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output (decoded):\n",
            "<bos><bos><start_of_turn>user\n",
            "how can I improve speaking skills<end_of_turn>\n",
            "<start_of_turn>model\n",
            "**1. Practice Regularly:**\n",
            "- Engage in conversations with native speakers or practice with a language partner.\n",
            "- Join a language exchange group or online forum.\n",
            "- Record yourself speaking and listen back to identify areas for improvement.\n",
            "\n",
            "**2. Focus on Pronunciation:**\n",
            "- Pay attention to the sounds of the language, including intonation, rhythm, and stress.\n",
            "- Use pronunciation tools and recordings to learn correct pronunciation.\n",
            "- Practice speaking words and phrases out loud, focusing on different accents.\n",
            "\n",
            "**3. Expand Your Vocabulary:**\n",
            "- Read extensively in the target language, both fiction and non-fiction.\n",
            "- Listen to podcasts, audiobooks, and music in the language.\n",
            "- Use flashcards and spaced repetition techniques to learn new words.\n",
            "\n",
            "**4. Read Fluently:**\n",
            "- Start with children's books or simple texts and gradually progress to more complex materials.\n",
            "- Pay attention to grammar, punctuation, and sentence structure.\n",
            "- Use a dictionary and thesaurus to find synonyms and antonyms.\n",
            "\n",
            "**5. Use Visual Aids:**\n",
            "- Use flashcards, diagrams, and other visual aids to support your spoken language.\n",
            "- Watch movies and TV shows with subtitles to improve comprehension and pronunciation.\n",
            "\n",
            "**6. Record and Reflect:**\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input text: {input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt, '').replace('<bos>', '').replace('<eos>', '')}\")"
      ],
      "metadata": {
        "id": "AOLj6f53Y6QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bab867-5827-41c1-92c2-44b0db27fc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: how can I improve speaking skills\n",
            "\n",
            "Output text:\n",
            "**1. Practice Regularly:**\n",
            "- Engage in conversations with native speakers or practice with a language partner.\n",
            "- Join a language exchange group or online forum.\n",
            "- Record yourself speaking and listen back to identify areas for improvement.\n",
            "\n",
            "**2. Focus on Pronunciation:**\n",
            "- Pay attention to the sounds of the language, including intonation, rhythm, and stress.\n",
            "- Use pronunciation tools and recordings to learn correct pronunciation.\n",
            "- Practice speaking words and phrases out loud, focusing on different accents.\n",
            "\n",
            "**3. Expand Your Vocabulary:**\n",
            "- Read extensively in the target language, both fiction and non-fiction.\n",
            "- Listen to podcasts, audiobooks, and music in the language.\n",
            "- Use flashcards and spaced repetition techniques to learn new words.\n",
            "\n",
            "**4. Read Fluently:**\n",
            "- Start with children's books or simple texts and gradually progress to more complex materials.\n",
            "- Pay attention to grammar, punctuation, and sentence structure.\n",
            "- Use a dictionary and thesaurus to find synonyms and antonyms.\n",
            "\n",
            "**5. Use Visual Aids:**\n",
            "- Use flashcards, diagrams, and other visual aids to support your spoken language.\n",
            "- Watch movies and TV shows with subtitles to improve comprehension and pronunciation.\n",
            "\n",
            "**6. Record and Reflect:**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation."
      ],
      "metadata": {
        "id": "83ms8e7ya_cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IELTS-style questions generated with GPT-4\n",
        "gpt4_questions = [\n",
        "    \"What are the best strategies to improve your IELTS speaking score?\",\n",
        "    \"How can you effectively manage time during the IELTS reading test?\",\n",
        "    \"Describe techniques to write a high-scoring IELTS essay.\",\n",
        "    \"What role does vocabulary play in the IELTS listening section?\",\n",
        "    \"Explain the importance of practicing mock tests for the IELTS exam.\",\n",
        "    \"How can you build fluency for the IELTS speaking test?\",\n",
        "]\n",
        "\n",
        "# Manually created question list\n",
        "manual_questions = [\n",
        "    \"What are common mistakes to avoid in the IELTS writing task?\",\n",
        "    \"How should you prepare for the IELTS listening section?\",\n",
        "    \"What is the ideal structure for an IELTS Task 2 essay?\",\n",
        "    \"What are the key differences between IELTS Academic and General Training?\",\n",
        "    \"How can you improve your band score in the IELTS reading test?\",\n",
        "]\n",
        "\n",
        "# Combine GPT-4 generated and manually created questions\n",
        "query_list = gpt4_questions + manual_questions"
      ],
      "metadata": {
        "id": "NvO5OslGa_7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now let's check if our `retrieve_relevant_resources()` function works with our list of queries."
      ],
      "metadata": {
        "id": "rF-UKnpub6i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "query = random.choice(query_list)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "scores, indices"
      ],
      "metadata": {
        "id": "hNxLsPs4b6_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbc27f1-495b-406b-faa0-7202d4d40407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are common mistakes to avoid in the IELTS writing task?\n",
            "[INFO] Time taken to get scores on 30 embeddings: 0.00009 seconds.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.4694, 0.4677, 0.4606, 0.4605, 0.4586], device='cuda:0'),\n",
              " tensor([12, 23,  4, 17,  0], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Augmenting our prompt with context items**"
      ],
      "metadata": {
        "id": "ovC3lfbZcgp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_formatter(query: str, context_items: list[dict]) -> str:\n",
        "    \"\"\"\n",
        "    Augments query with text-based context from context_items.\n",
        "    \"\"\"\n",
        "    # Join context items into a single paragraph\n",
        "    context = \"\\n\\n\".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "    # Create the improved base prompt\n",
        "    base_prompt = f\"\"\"Based on the following context items, provide the most helpful and detailed answer to the query below.\n",
        "    If you cannot find relevant information in the provided context, use your general knowledge and logical reasoning to generate a well-informed, accurate, and practical answer.\n",
        "    Ensure that your response remains factual, logical, and does not speculate beyond reasonable assumptions.\n",
        "\n",
        "    Before generating the final answer, show your thought process step by step. These steps should include:\n",
        "    1. Identifying relevant information from the provided context (if available).\n",
        "    2. Explaining how the context or your reasoning is applied to answer the query.\n",
        "    3. Highlighting any assumptions made if the context is insufficient.\n",
        "\n",
        "    Finally, provide your answer in a clear and concise manner. Use the following examples as a reference for the ideal answer style. Your answer should not include the examples themselves, only follow their structure and tone.\n",
        "\n",
        "    Example 1:\n",
        "    Query: What are the best strategies to improve your IELTS speaking score?\n",
        "    Answer: To improve your IELTS speaking score, focus on fluency and coherence by practicing speaking with friends or recording yourself and listening for areas of improvement. Expand your vocabulary by learning phrases and idioms relevant to common IELTS topics, such as education, environment, and technology. Additionally, practice answering past IELTS speaking questions under timed conditions to simulate the test environment.\n",
        "\n",
        "    Example 2:\n",
        "    Query: How can you effectively manage time during the IELTS reading test?\n",
        "    Answer: To manage time effectively during the IELTS reading test, start by quickly skimming the passage to get a general idea of its content. Then, read the questions and underline key information. Divide your time equally across the three sections, spending no more than 20 minutes per section. If you encounter difficult questions, move on and return to them later if time permits.\n",
        "\n",
        "    Example 3:\n",
        "    Query: What is the ideal structure for an IELTS Writing Task 2 essay?\n",
        "    Answer: A high-scoring IELTS Writing Task 2 essay should include an introduction that clearly states your position, two or three body paragraphs with arguments supported by examples, and a conclusion that summarizes your key points. Ensure coherence and cohesion by using linking words such as \"however,\" \"therefore,\" and \"in addition.\" Also, proofread your essay to avoid grammatical mistakes and spelling errors.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Query: {query}\n",
        "\n",
        "    Explain your thought process step by step:\n",
        "    1. ...\n",
        "    2. ...\n",
        "    3. ...\n",
        "\n",
        "    Final Answer:\"\"\"\n",
        "\n",
        "    # Update the base prompt with context items and query\n",
        "    dialogue_template = [\n",
        "        {\"role\": \"user\", \"content\": base_prompt}\n",
        "    ]\n",
        "\n",
        "    # Generate the prompt\n",
        "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                          tokenize=False,\n",
        "                                          add_generation_prompt=True)\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "ieD0LrCgchGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try our function out."
      ],
      "metadata": {
        "id": "v2ycKD7keG8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Get relevant resources\n",
        "scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                              embeddings=embeddings)\n",
        "\n",
        "# Create a list of context items\n",
        "context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "# Format prompt with context items\n",
        "prompt = prompt_formatter(query=query,\n",
        "                          context_items=context_items)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "vJ9vREqYeHSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f302ec09-86a4-4598-b024-40a071ac96a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the key differences between IELTS Academic and General Training?\n",
            "[INFO] Time taken to get scores on 30 embeddings: 0.00008 seconds.\n",
            "<bos><start_of_turn>user\n",
            "Based on the following context items, provide the most helpful and detailed answer to the query below.\n",
            "    If you cannot find relevant information in the provided context, use your general knowledge and logical reasoning to generate a well-informed, accurate, and practical answer.\n",
            "    Ensure that your response remains factual, logical, and does not speculate beyond reasonable assumptions.\n",
            "\n",
            "    Before generating the final answer, show your thought process step by step. These steps should include:\n",
            "    1. Identifying relevant information from the provided context (if available).\n",
            "    2. Explaining how the context or your reasoning is applied to answer the query.\n",
            "    3. Highlighting any assumptions made if the context is insufficient.\n",
            "\n",
            "    Finally, provide your answer in a clear and concise manner. Use the following examples as a reference for the ideal answer style. Your answer should not include the examples themselves, only follow their structure and tone.\n",
            "\n",
            "    Example 1:\n",
            "    Query: What are the best strategies to improve your IELTS speaking score?\n",
            "    Answer: To improve your IELTS speaking score, focus on fluency and coherence by practicing speaking with friends or recording yourself and listening for areas of improvement. Expand your vocabulary by learning phrases and idioms relevant to common IELTS topics, such as education, environment, and technology. Additionally, practice answering past IELTS speaking questions under timed conditions to simulate the test environment.\n",
            "\n",
            "    Example 2:\n",
            "    Query: How can you effectively manage time during the IELTS reading test?\n",
            "    Answer: To manage time effectively during the IELTS reading test, start by quickly skimming the passage to get a general idea of its content. Then, read the questions and underline key information. Divide your time equally across the three sections, spending no more than 20 minutes per section. If you encounter difficult questions, move on and return to them later if time permits.\n",
            "\n",
            "    Example 3:\n",
            "    Query: What is the ideal structure for an IELTS Writing Task 2 essay?\n",
            "    Answer: A high-scoring IELTS Writing Task 2 essay should include an introduction that clearly states your position, two or three body paragraphs with arguments supported by examples, and a conclusion that summarizes your key points. Ensure coherence and cohesion by using linking words such as \"however,\" \"therefore,\" and \"in addition.\" Also, proofread your essay to avoid grammatical mistakes and spelling errors.\n",
            "\n",
            "    Context:\n",
            "    The \r \r \r the chick to leave \r \r and so lend to \r \r \r it again and the \r \r \r experiment had \r \r \r the nest and fly. \r \r be found in and \r \r \r results showed a \r \r \r failed and, as a re$uft, \r \r \r \r around tropica! \r \r \r significant change in \r \r \r the public grew \r \r \r \r rainforests. \r \r \r temperature when the \r \r \r angry at the waste \r \r \r \r \r \r insulation was used. \r \r \r of public funds. \r \r \r \r \r Types of information \r \r 1 the findings of a study \r \r 2 the method used in a research study \r \r 3 the rea ct ion to someth t n g \r \r 4 a description of a habitat \r \r 5 the difference between current and past studies \r \r 6 a description of how something works \r \r 7 the cause of something \r \r 8 the amount of time needed for something \r \r \r 2 Locating and matching information \r \r Just like matching headings, matching information questions are \r not in the same order as the passage. \r \r \r Study Tip Some examples of the type of information you may be \r asked to find are: \r \r * a finding \r \r \r • a number \r ■ a date \r \r • a measurement \r \r • a reason \r \r \r • a cause \r \r « an effect \r \r • a conclusion \r \r • the probfems \r \r \r an account \r a reaction \r a description. \r \r \r When you are reading different passages in this book, think about \r whether the information matches any of these types. \r \r \r 60 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2.1 Spend two minutes skim reading ike passage below, so ihai you are \r familiar wiili (he type of information it contains. \r \r What is the main purpose of ihe passage?\n",
            "\n",
            "3.3 Read statements 4-8, then underline ihc relevant parts in the text. Arc the \r statements True, False or Nci Given? \r \r 4 Atiania has experienced more dramatic weather change than other areas of the US. \r \r 5 Roofs that are dark in colour help address the issue of Urban Heat islands. \r \r 6 Singapore's Supenrees are made entirely from natural materials. \r \r 7 The designers of the Supertrees originally planned to plant very tall trees. \r \r 8 The Superirees require regular maintenance. \r \r \r 3.4 Read statements 1-8 again and correct any that were false. \r \r \r 58 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r information \r \r In this unit you will practise: \r \r • identifying types of information \r \r • locating and matching information \r \r • connecting ideas \r \r • matching sentence endings \r \r • matching information \r \r v**' vv w E1- + 'f m \r \r \r t Identifying types of information \r \r For matching information tasks, you need to locate ail idea or piece of \r information in the texi and match it to a phrase that accurately describes it. \r \r \r 1.1 Read the extracts from two separate paragraphs of a Reading \r passage.\n",
            "\n",
            "61 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2.2 Look at tliis task based on (he Reading passage. For each \r \r question, underline the type of information you need to scan Tor. \r The first two have been done for you. \r \r \r Which paragraph contains the following information? \r \r N. B You may use any letter more than once \r \r Write the correct letter. A-E, next to questions 1-7 below, \r \r 1 visual evidence of the gecko's ability to resist water \r \r 2 a question that is yet to be answered by the researchers \r \r 3 the method used to calculate the gripping power of geckos \r \r 4 the researcher's opinion of the gecko’s gripping ability \r \r 5 a mention of the different environments where geckos can be found \r \r 6 the contrast between Stark's research and the work of other researchers \r \r 7 the definition of a scientific term \r \r \r 2.3 It is important to fully understand what you are looking for in \r the passage. Answer these questions, based on Question I in the \r task above, \r \r 1 Which of the following do you think is 'visual evidence’? \r \r A som et hing the re sea re he rs belie ve \r B something the researchers have seen \r C something the researchers have read about \r \r 2 Which of the following means the same as 'ability to resist \r water'? \r \r A soaks up water \r B sinks in water \r C stops water getting in \r \r 3 Scan the passage to find 'visual evidence' of an ability to resist \r water, which paragraph contains this information? \r \r 2.4 Study Questions 2-7 in 2.2 carefully and match them to \r paragraphs A-E. Remember, the questions are not in the same \r order as the passage.\n",
            "\n",
            "You need to \r focus on the whole idea \r of each paragraph. \r \r \r 56 \r \r \r \r \r \r \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2 Understanding the main points \r \r Another type of question that can fbtus on the main point of a \r paragraph is multiple choice. This type of question often requires \r you to carefully read more ilian one sentence in the paragraph, \r \r 2*1 Look at this question, based on the passage in 1.2. \r \r I In Paragraph A, what is the main point that the writer makes? \r \r A Some urban designs are better in theory than in practice. \r \r 8 The urban-planning concept itself is not restricted to \r modern times. \r \r C Urban planning should be carried out by professionals. \r r> Some planned ancient cities are more successful than \r modern ones. \r \r 2.2 The parte of Paragraph A relating to each option are underlined \r below, Read the paragraph carefully and choose the correct \r option, A-D. \r \r \r 5 The notion pj panning gnbr e.communities Poor to their construction is an ancient on* . ; In fact, one nf tho \r cities pn record is Miletus.\n",
            "\n",
            "[fudging from] the complexity of the material that has been collected from different parts of the landscape \r and brought to the site, they | the people] must have had an elementary knowledge of chemistry to be able to \r combine these materials to produce ibis form. Its not a straightforward process,™ said Henshilwood. \r \r \r 1 *2 Scanning involves searching a text quickly for a specific piece \r of information. Practise scanning the passage for the words/ \r numbers in the box. \r \r \r 75,000 100,000 200,000 artefacts ochre \r \r \r 48 \r \r \r \r \r \r \r \r \r Reading skills \r \r \r 2 Using words from the passage \r \r Their are several types of question that ask you to write a word and/or \r number from the passage. \r \r * You will be told the maximum number of words to write. \r \r * You must only write words that are in the passage. Make sure you \r copy the spelling correctly, \r \r 1 ^ ^ need to change the words in the passage and you do not \r need to join words together. \r \r II um w rite tuo many words or make a spelling mistake, your answer \r wilt he marked wrong. \r \r Test Tip if the question asks you to write TWO WORDS AND/OR A \r NUMBER, this means the answer may be: \r \r * one word \r \r * one word + a number \r ■ two words \r \r * two words + a number \r \r Remember that even if a number is written as a word, it counts as a \r number (e.g. twenty five trees = one word and a number).\n",
            "\n",
            "    Query: What are the key differences between IELTS Academic and General Training?\n",
            "\n",
            "    Explain your thought process step by step:\n",
            "    1. ...\n",
            "    2. ...\n",
            "    3. ...\n",
            "\n",
            "    Final Answer:<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tokenize this and pass it straight to our LLM."
      ],
      "metadata": {
        "id": "2D4sSDxleRlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Generate an output of tokens\n",
        "outputs = llm_model.generate(**input_ids,\n",
        "                             temperature=0.7, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
        "                             do_sample=True,\n",
        "                             max_new_tokens=256) # how many new tokens to generate from prompt\n",
        "\n",
        "# Turn the output tokens into text\n",
        "output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
      ],
      "metadata": {
        "id": "GilYoyKaeSu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0568df-0667-4b1a-a12b-a7c322beab11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the key differences between IELTS Academic and General Training?\n",
            "RAG answer:\n",
            "<bos>**Thought Process:**\n",
            "\n",
            "**1. Identifying Relevant Information**\n",
            "\n",
            "* The passage does not provide any directly relevant information about IELTS Academic and General Training, so I cannot identify any key differences between the two programs from the context.\n",
            "\n",
            "**2. Explaining Reasoning**\n",
            "\n",
            "I am unable to generate a response because the context does not provide any information about the key differences between IELTS Academic and General Training.\n",
            "\n",
            "**3. Assumptions Made**\n",
            "\n",
            "The context does not provide any assumptions, so I cannot generate a response.<eos>\n",
            "CPU times: user 3.31 s, sys: 5.68 ms, total: 3.31 s\n",
            "Wall time: 3.31 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we functionize the generation step to make it easier to use?"
      ],
      "metadata": {
        "id": "fFwUIxtlfI4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(query,\n",
        "        temperature=0.7,\n",
        "        max_new_tokens=512,\n",
        "        format_answer_text=True,\n",
        "        return_answer_only=True):\n",
        "    \"\"\"\n",
        "    Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get just the scores and indices of top related results\n",
        "    scores, indices = retrieve_relevant_resources(query=query,\n",
        "                                                  embeddings=embeddings)\n",
        "\n",
        "    # Create a list of context items\n",
        "    context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "    # Add score to context item\n",
        "    for i, item in enumerate(context_items):\n",
        "        item[\"score\"] = scores[i].cpu() # return score back to CPU\n",
        "\n",
        "    # Format the prompt with context items\n",
        "    prompt = prompt_formatter(query=query,\n",
        "                              context_items=context_items)\n",
        "\n",
        "    # Tokenize the prompt\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    # Generate an output of tokens\n",
        "    outputs = llm_model.generate(**input_ids,\n",
        "                                 temperature=temperature,\n",
        "                                 do_sample=True,\n",
        "                                 max_new_tokens=max_new_tokens)\n",
        "\n",
        "    # Turn the output tokens into text\n",
        "    output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "    if format_answer_text:\n",
        "        # Replace special tokens and unnecessary help message\n",
        "        output_text = output_text.replace(prompt, \"\").replace(\"<bos>\", \"\").replace(\"<eos>\", \"\").replace(\"Sure, here is the answer to the user query:\\n\\n\", \"\")\n",
        "\n",
        "    # Only return the answer without the context items\n",
        "    if return_answer_only:\n",
        "        return output_text\n",
        "\n",
        "    return output_text, context_items"
      ],
      "metadata": {
        "id": "6ldd4z9HfJXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it out."
      ],
      "metadata": {
        "id": "2_b5Q8H-fQJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random.choice(query_list)"
      ],
      "metadata": {
        "id": "usREzY8stnZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = random.choice(query_list)\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "# Answer query with context and return context\n",
        "answer, context_items = ask(query=query,\n",
        "                            temperature=0.7,\n",
        "                            max_new_tokens=512,\n",
        "                            return_answer_only=False)\n",
        "\n",
        "print(f\"Answer:\\n\")\n",
        "print_wrapped(answer)\n",
        "# print(f\"Context items:\")\n",
        "#context_items"
      ],
      "metadata": {
        "id": "GoqWop0xfQwV",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6298907a-8dfa-4b88-9378-5f2d5ccfb52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the best strategies to improve your IELTS speaking score?\n",
            "[INFO] Time taken to get scores on 30 embeddings: 0.00007 seconds.\n",
            "Answer:\n",
            "\n",
            "## Thought process:  **Step 1: Identifying relevant information**  * The context\n",
            "mentions that improving your IELTS speaking score requires practicing speaking\n",
            "with friends or recording yourself and listening for areas of improvement. * It\n",
            "also suggests learning phrases and idioms relevant to common IELTS topics. *\n",
            "These suggest that practicing speaking in a social setting, learning vocabulary,\n",
            "and being familiar with idiomatic expressions are key strategies for improving\n",
            "speaking skills.  **Step 2: Applying the context**  The context advises\n",
            "practicing speaking with friends, recording yourself, and listening for areas of\n",
            "improvement. It also suggests learning vocabulary and idioms relevant to common\n",
            "IELTS topics.  **Step 3: Assumptions**  * The context does not provide any\n",
            "specific information or guidelines for practicing speaking in a social setting.\n",
            "* The context does not provide any specific information or guidelines for\n",
            "learning vocabulary and idioms.  **Final answer:**  The best strategies to\n",
            "improve your IELTS speaking score are:  1. Practice speaking with friends in a\n",
            "social setting. 2. Learn vocabulary and idioms relevant to common IELTS topics.\n",
            "3. Listen for areas of improvement in your spoken English and practice speaking\n",
            "accordingly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Text to speech model**"
      ],
      "metadata": {
        "id": "90rpff4kPH_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Using the gemma-2b-it model\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "\n",
        "# Loading the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Set chat_template correctly\n",
        "tokenizer.chat_template = \"{% for message in messages %}{{ '<|im_start|>' + message['role'] + '\\\\n' + message['content'] + '\\\\n' }}{% endfor %}\"\n",
        "\n",
        "# Loading the model\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "\n",
        "# Move the model to the GPU (if available)\n",
        "llm_model.to(\"cuda\")\n",
        "\n",
        "print(\"The model and tokenizer were successfully loaded, and the chat_template was set!\")\n"
      ],
      "metadata": {
        "id": "KcME0xQUJNhp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "6d3348a8b4bc41a8b8428f64cfa783a3",
            "e4047c65b5264b9baa3eee7ab08d5e1f",
            "7348dc2b42694cc5bc79836402d0ae40",
            "579c1c9652f74ef8a99cb24cd5310481",
            "80b4a63993af4d708004221ee609587f",
            "53466267c6504e81af1543d8d4ecf949",
            "395ea9816f39402cbdcc0fad6850fb7a",
            "e9355e98807145428869fce26526716a",
            "eae063bb8c5c48ad95e63cbc49ffabb5",
            "309d9d6fe1f14c17a43746055bf8bb07",
            "8745a14fd5ba4f0db8b27c8266c85cba"
          ]
        },
        "outputId": "7b9d9ce6-88d0-4596-c946-63015827ce0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d3348a8b4bc41a8b8428f64cfa783a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "模型和 tokenizer 已成功加载，并设置了 chat_template！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.51.3 accelerate==1.6.0 --no-warn-script-location --quiet"
      ],
      "metadata": {
        "id": "PjKKCs7XtioN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers accelerate\n"
      ],
      "metadata": {
        "id": "ynfGrXxPVeOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VitsModel, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "\n",
        "text = answer\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(**inputs).waveform\n"
      ],
      "metadata": {
        "id": "J4mOM-XRVeMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(output.numpy(), rate=model.config.sampling_rate)"
      ],
      "metadata": {
        "id": "l9yrJ_1fVeJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io.wavfile import write\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "\n",
        "# Assume `output` is the generated audio data (Tensor) with sampling rate `model.config.sampling_rate`\n",
        "sampling_rate = model.config.sampling_rate\n",
        "output_filename = \"generated_audio.wav\"\n",
        "\n",
        "# 1. Convert audio data to numpy array\n",
        "audio_data = output.numpy()  # 转换为 numpy 数组\n",
        "\n",
        "# 2. Check the range of the audio data and normalize it to [-1.0, 1.0]\n",
        "# If the data range is not [-1.0, 1.0], you need to normalize it first\n",
        "if audio_data.min() < -1.0 or audio_data.max() > 1.0:\n",
        "    audio_data = audio_data / np.max(np.abs(audio_data))  # Normalized to [-1.0, 1.0]\n",
        "\n",
        "# 3. Make sure the audio data is a one-dimensional array (mono)\n",
        "if len(audio_data.shape) > 1:\n",
        "    audio_data = audio_data.squeeze()  # Remove redundant dimensions\n",
        "\n",
        "# 4. Convert data from [-1.0, 1.0] to int16 range [-32768, 32767]\n",
        "audio_data = (audio_data * 32767).astype(np.int16)\n",
        "\n",
        "# 5. Save audio to .wav file\n",
        "write(output_filename, sampling_rate, audio_data)\n",
        "\n",
        "# 6. Download the audio file to your local computer\n",
        "files.download(output_filename)"
      ],
      "metadata": {
        "id": "uyoZ6VNiNMYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "734126f2-563c-477c-c2b9-dc41581f4a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c459f7a5-f3d5-402d-9f7d-2de52c2bc919\", \"generated_audio.wav\", 2314284)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)  # Check if the current tokenizer is correct\n",
        "print(hasattr(tokenizer, \"chat_template\"))  # Check if chat_template is set"
      ],
      "metadata": {
        "id": "AmMJnm1tVeGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa7a449f-9b6a-49e2-ea0a-19e20cc9bb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VitsTokenizer(name_or_path='facebook/mms-tts-eng', vocab_size=38, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '<unk>', 'pad_token': 'k'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
            "\t0: AddedToken(\"k\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t38: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**SoVITS model**"
      ],
      "metadata": {
        "id": "Mj2tTXxGp_R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/setup.sh\n",
        "set -e\n",
        "cd /content\n",
        "rm -rf GPT-SoVITS\n",
        "git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
        "cd GPT-SoVITS\n",
        "\n",
        "if conda env list | awk '{print $1}' | grep -Fxq \"GPTSoVITS\"; then\n",
        "    :\n",
        "else\n",
        "    conda create -n GPTSoVITS python=3.10 -y\n",
        "fi\n",
        "\n",
        "source activate GPTSoVITS\n",
        "\n",
        "bash install.sh --source HF --download-uvr5"
      ],
      "metadata": {
        "id": "FfHewNE_p4Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh\")\n",
        "!cd /content && bash setup.sh"
      ],
      "metadata": {
        "id": "qBO_E3Bop4Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/GPT-SoVITS && source activate GPTSoVITS && export is_share=True && python webui.py"
      ],
      "metadata": {
        "id": "_yYpXYZep4G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Gradio with writing evluating system+ tts + system workflow**"
      ],
      "metadata": {
        "id": "1fES_EktpboT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Knz8xeekLPHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a68eac-2aee-46d5-cd33-3bc8eb6473f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.26.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.9.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.9.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio requests"
      ],
      "metadata": {
        "id": "vsLLcMIVOi2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ef0c2f-3fc0-4178-cdf0-a5a186b48d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.26.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.9.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.9.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.9.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xP7G32vTD70x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, VitsModel, AutoTokenizer as TTSTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Add language detection function\n",
        "def detect_language(text):\n",
        "    \"\"\"Detect whether the text is Chinese or English\"\"\"\n",
        "    # Simple judgment: if it contains Chinese characters, it is considered Chinese\n",
        "    for char in text:\n",
        "        if '\\u4e00' <= char <= '\\u9fff':\n",
        "            return \"zh\"\n",
        "    return \"en\"\n",
        "\n",
        "# 1. Load existing models and data\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\").to(device)\n",
        "\n",
        "# Simple user data storage\n",
        "user_progress = {}\n",
        "\n",
        "# Load your text data and embeddings\n",
        "try:\n",
        "    import pandas as pd\n",
        "    text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
        "    # Transform Embed\n",
        "    text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(\n",
        "        lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
        "    pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
        "    embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()),\n",
        "                              dtype=torch.float32).to(device)\n",
        "    print(\"✅ Successfully loaded data\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to load data: {e}\")\n",
        "    # If the data loading fails, you can provide some sample data\n",
        "    pages_and_chunks = []\n",
        "    embeddings = None\n",
        "\n",
        "# 2. Load LLM\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Add TTS model (lazy loading to save memory)\n",
        "tts_model = None\n",
        "tts_tokenizer = None\n",
        "\n",
        "def load_tts_model():\n",
        "    global tts_model, tts_tokenizer\n",
        "    if tts_model is None:\n",
        "        print(\"Loading TTS model...\")\n",
        "        tts_model = VitsModel.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "        tts_tokenizer = TTSTokenizer.from_pretrained(\"facebook/mms-tts-eng\")\n",
        "        print(\"✅ TTS model loaded\")\n",
        "    return tts_model, tts_tokenizer\n",
        "\n",
        "# 3. Define retrieval and generation functions\n",
        "def retrieve_relevant_resources(query, embeddings, n_resources=5):\n",
        "    \"\"\"Search for related resources\"\"\"\n",
        "    query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "    dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "    scores, indices = torch.topk(dot_scores, k=n_resources)\n",
        "    return scores, indices\n",
        "\n",
        "def generate_answer(query, context_items, avg_relevance_score=0.0):\n",
        "    \"\"\"Generate answers, determine the answer language based on the query language, and decide whether to use the search content based on relevance\"\"\"\n",
        "    # Set a relevance threshold below which LLM knowledge is used instead of search content\n",
        "    relevance_threshold = 0.65\n",
        "\n",
        "    # All output uses English by default\n",
        "    language = \"en\"\n",
        "\n",
        "    # Determine the prompt content based on relevance\n",
        "    if avg_relevance_score < relevance_threshold:\n",
        "        # Low relevance, let the model use its own knowledge\n",
        "        prompt = f\"\"\"Here is a question about the IELTS exam. Since no sufficiently relevant reference materials were found, please use your own knowledge to answer.\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    else:\n",
        "        # Highly relevant, using the retrieved content\n",
        "        context = \"\\n\\n\".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "        prompt = f\"\"\"Based on the following IELTS materials, answer the question:\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\")\n",
        "    return response, language\n",
        "\n",
        "def evaluate_response_quality(query, response, relevance_score):\n",
        "    \"\"\"Evaluate the quality of the system's answers\"\"\"\n",
        "    # Evaluate based on relevance and heuristic rules\n",
        "    coherence_score = min(1.0, 0.5 + relevance_score * 0.5)  # Simple heuristic rules\n",
        "\n",
        "    # Generate English evaluation report\n",
        "    if relevance_score > 0.8:\n",
        "        relevance_comment = \"Highly Relevant - The answer directly addresses the core of the question\"\n",
        "    elif relevance_score > 0.6:\n",
        "        relevance_comment = \"Relevant - The answer covers main aspects of the question\"\n",
        "    else:\n",
        "        relevance_comment = \"Partially Relevant - The answer only partially addresses the question\"\n",
        "\n",
        "    # Text length evaluation\n",
        "    if len(response) < 50:\n",
        "        length_comment = \"Too Short - The answer may not be comprehensive\"\n",
        "    elif len(response) > 500:\n",
        "        length_comment = \"Extensive - The answer is very comprehensive\"\n",
        "    else:\n",
        "        length_comment = \"Adequate - The answer length is reasonable\"\n",
        "\n",
        "    # Portfolio Assessment Report\n",
        "    report = f\"\"\"\n",
        "### Answer Quality Assessment\n",
        "\n",
        "**Relevance**: {relevance_score:.2f}/1.0 - {relevance_comment}\n",
        "**Coherence**: {coherence_score:.2f}/1.0\n",
        "**Length**: {len(response)} characters - {length_comment}\n",
        "\n",
        "**Overall Rating**: {(relevance_score + coherence_score) / 2:.2f}/1.0\n",
        "    \"\"\"\n",
        "\n",
        "    return report\n",
        "\n",
        "def process_query(query):\n",
        "    \"\"\"Processes the query and returns results and performance indicators (improved version with relevance evaluation)\"\"\"\n",
        "    # Check if data has been loaded\n",
        "    if embeddings is None:\n",
        "        return \"Data not loaded, please run the data processing code first\", \"\", \"Performance metrics unavailable: data not loaded\"\n",
        "\n",
        "    # Recording start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Get relevant resources\n",
        "    retrieval_start = time.time()\n",
        "    scores, indices = retrieve_relevant_resources(query, embeddings)\n",
        "    retrieval_time = time.time() - retrieval_start\n",
        "\n",
        "    context_items = [pages_and_chunks[i] for i in indices]\n",
        "\n",
        "    # Calculate the average relevance score\n",
        "    avg_relevance = scores.mean().item()\n",
        "\n",
        "    # Record generation start time\n",
        "    generation_start = time.time()\n",
        "\n",
        "    # Generate Answer (now passes relevance score)\n",
        "    answer, detected_language = generate_answer(query, context_items, avg_relevance)\n",
        "\n",
        "    # Calculate generation time\n",
        "    generation_time = time.time() - generation_start\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    # Preparing context information for display\n",
        "    context_display = \"\"\n",
        "    for i, (score, idx) in enumerate(zip(scores, indices)):\n",
        "        context_display += f\"**Reference {i+1}** (Relevance: {score:.2f}):\\n{pages_and_chunks[idx]['sentence_chunk'][:200]}...\\n\\n\"\n",
        "\n",
        "    # Quality Assessment\n",
        "    quality_report = evaluate_response_quality(query, answer, avg_relevance)\n",
        "\n",
        "    # Preparing performance indicators\n",
        "    metrics = f\"\"\"\n",
        "### System Performance Metrics\n",
        "- **Retrieval Time**: {retrieval_time:.2f} seconds\n",
        "- **Generation Time**: {generation_time:.2f} seconds\n",
        "- **Total Response Time**: {total_time:.2f} seconds\n",
        "- **Average Relevance Score**: {avg_relevance:.4f}/1.0\n",
        "- **Response Mode**: {\"Retrieved Context\" if avg_relevance >= 0.65 else \"LLM Knowledge\"}\n",
        "{quality_report}\n",
        "\"\"\"\n",
        "\n",
        "    return answer, context_display, metrics\n",
        "\n",
        "def process_query_with_history(query, history=\"\"):\n",
        "    \"\"\"Processing queries and saving history\"\"\"\n",
        "    answer, context, metrics = process_query(query)\n",
        "\n",
        "    # Update History\n",
        "    timestamp = time.strftime(\"%H:%M:%S\")\n",
        "    new_history = f\"{history}<hr><b>[{timestamp}] Q:</b> {query}<br><b>A:</b> {answer}<br>\"\n",
        "\n",
        "    return answer, context, metrics, new_history\n",
        "\n",
        "def track_user_activity(username, activity_type, content, score=None):\n",
        "    \"\"\"Tracking user learning activities\"\"\"\n",
        "    if username not in user_progress:\n",
        "        user_progress[username] = {\n",
        "            \"queries\": [],\n",
        "            \"writing_samples\": [],\n",
        "            \"practice_tests\": [],\n",
        "            \"last_active\": None\n",
        "        }\n",
        "\n",
        "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    if activity_type == \"query\":\n",
        "        user_progress[username][\"queries\"].append({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"query\": content,\n",
        "            \"relevance_score\": score\n",
        "        })\n",
        "    elif activity_type == \"writing\":\n",
        "        user_progress[username][\"writing_samples\"].append({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"sample\": content[:100] + \"...\",  # Save Summary\n",
        "            \"score\": score\n",
        "        })\n",
        "    elif activity_type == \"practice\":\n",
        "        user_progress[username][\"practice_tests\"].append({\n",
        "            \"timestamp\": timestamp,\n",
        "            \"test_type\": content,\n",
        "            \"completed\": True\n",
        "        })\n",
        "\n",
        "    user_progress[username][\"last_active\"] = timestamp\n",
        "\n",
        "    # Build Progress Summary\n",
        "    summary = f\"\"\"\n",
        "### Learning Progress Summary ({username})\n",
        "- Questions asked: {len(user_progress[username][\"queries\"])}\n",
        "- Writing samples: {len(user_progress[username][\"writing_samples\"])}\n",
        "- Practice tests: {len(user_progress[username][\"practice_tests\"])}\n",
        "- Last active: {user_progress[username][\"last_active\"]}\n",
        "\n",
        "#### Recent Activity\n",
        "\"\"\"\n",
        "\n",
        "    # Add the last 5 events\n",
        "    recent_queries = user_progress[username][\"queries\"][-3:] if user_progress[username][\"queries\"] else []\n",
        "    recent_writings = user_progress[username][\"writing_samples\"][-2:] if user_progress[username][\"writing_samples\"] else []\n",
        "\n",
        "    for q in recent_queries:\n",
        "        summary += f\"- [{q['timestamp']}] Question: {q['query'][:50]}...\\n\"\n",
        "\n",
        "    for w in recent_writings:\n",
        "        summary += f\"- [{w['timestamp']}] Writing practice\\n\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "def process_query_with_tracking(query, username):\n",
        "    \"\"\"Handle inquiries and track learning progress\"\"\"\n",
        "    answer, context, metrics = process_query(query)\n",
        "\n",
        "    # Extracting relevance scores from metrics\n",
        "    import re\n",
        "    relevance_match = re.search(r\"Average Relevance Score: ([\\d\\.]+)\", metrics)\n",
        "    relevance_score = float(relevance_match.group(1)) if relevance_match else None\n",
        "\n",
        "    # Track this query\n",
        "    progress = track_user_activity(username, \"query\", query, relevance_score)\n",
        "\n",
        "    return answer, context, metrics, progress\n",
        "\n",
        "# Modify the TTS function to ensure that the complete content is processed\n",
        "def text_to_speech(text):\n",
        "    \"\"\"Convert text to speech, process full English text\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "\n",
        "    # Load the TTS model (if not already loaded)\n",
        "    model, tokenizer = load_tts_model()\n",
        "\n",
        "    # If the text is too long, process it in segments and concatenate them\n",
        "    max_segment_length = 500  # Maximum length of each segment\n",
        "    segments = []\n",
        "\n",
        "    # Segment text\n",
        "    if len(text) > max_segment_length:\n",
        "        words = text.split()\n",
        "        current_segment = []\n",
        "        current_length = 0\n",
        "\n",
        "        for word in words:\n",
        "            current_length += len(word) + 1  # +1 for space\n",
        "            if current_length <= max_segment_length:\n",
        "                current_segment.append(word)\n",
        "            else:\n",
        "                segments.append(\" \".join(current_segment))\n",
        "                current_segment = [word]\n",
        "                current_length = len(word) + 1\n",
        "\n",
        "        if current_segment:\n",
        "            segments.append(\" \".join(current_segment))\n",
        "    else:\n",
        "        segments = [text]\n",
        "\n",
        "    # Process each paragraph and concatenate\n",
        "    full_waveform = None\n",
        "    sample_rate = None\n",
        "\n",
        "    for segment in segments:\n",
        "        inputs = tokenizer(segment, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs).waveform\n",
        "\n",
        "        if full_waveform is None:\n",
        "            full_waveform = output[0].numpy()\n",
        "            sample_rate = model.config.sampling_rate\n",
        "        else:\n",
        "            # Add a short pause (0.3 seconds of silence)\n",
        "            pause = np.zeros(int(0.3 * sample_rate))\n",
        "            full_waveform = np.concatenate([full_waveform, pause, output[0].numpy()])\n",
        "\n",
        "    # Return to full audio\n",
        "    return (sample_rate, full_waveform)\n",
        "\n",
        "# Text-to-speech language detection wrapper function\n",
        "def tts_with_language_check(text):\n",
        "    if not text:\n",
        "        return None, \"Please provide text content\"\n",
        "\n",
        "    language = detect_language(text)\n",
        "    if language == \"zh\":\n",
        "        return None, \"⚠️ Only English text is supported for TTS. Please provide English text.\"\n",
        "    else:\n",
        "        try:\n",
        "            audio = text_to_speech(text)\n",
        "            return audio, \"✅ Conversion successful! Full content converted to speech.\"\n",
        "        except Exception as e:\n",
        "            return None, f\"❌ Error during conversion: {str(e)}\"\n",
        "\n",
        "# Added IELTS writing scoring function\n",
        "def evaluate_ielts_writing(writing_sample, username=\"default_user\"):\n",
        "    \"\"\"Evaluate IELTS writing samples and keep track of records\"\"\"\n",
        "    if not writing_sample:\n",
        "        return \"Please provide a writing sample for evaluation.\"\n",
        "\n",
        "    prompt = f\"\"\"As an IELTS examiner, please assess the following student writing sample.\n",
        "    Provide scores and specific suggestions based on these criteria:\n",
        "    1. Task Response\n",
        "    2. Coherence and Cohesion\n",
        "    3. Lexical Resource\n",
        "    4. Grammatical Range and Accuracy\n",
        "\n",
        "    Give scores in 0.5 increments (e.g., 6.0, 6.5) for each category, and provide an overall score.\n",
        "\n",
        "    Student writing sample:\n",
        "    {writing_sample}\n",
        "\n",
        "    Score and detailed feedback:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.2,\n",
        "            do_sample=True\n",
        "        )\n",
        "    feedback = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\")\n",
        "\n",
        "    # Extract total score\n",
        "    import re\n",
        "    score_match = re.search(r\"Overall score.*?(\\d+\\.?\\d*)\", feedback)\n",
        "    overall_score = float(score_match.group(1)) if score_match else None\n",
        "\n",
        "    # Record writing activities\n",
        "    track_user_activity(username, \"writing\", writing_sample, overall_score)\n",
        "\n",
        "    return feedback\n",
        "\n",
        "# Added mock exam feature\n",
        "def generate_practice_question(section_type):\n",
        "    \"\"\"Generate IELTS practice questions\"\"\"\n",
        "    section_type_english = section_type.split(\" \")[0]  # Get the English section\n",
        "\n",
        "    prompt = f\"\"\"Create an IELTS {section_type_english} practice question.\n",
        "    Include detailed questions, guidance, and scoring criteria.\n",
        "    For Writing or Speaking sections, provide a sample question and response framework.\n",
        "    For Listening or Reading sections, provide sample questions and answer options.\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=512,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "    practice = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\")\n",
        "    return practice\n",
        "\n",
        "# Add learning plan generation function\n",
        "def generate_study_plan(target_score, weeks_available, strengths, weaknesses):\n",
        "    \"\"\"Generate a personalized IELTS study plan\"\"\"\n",
        "    prompt = f\"\"\"Create a personalized IELTS study plan with the following conditions:\n",
        "\n",
        "    Target Score: {target_score}\n",
        "    Available Time: {weeks_available} weeks\n",
        "    Strengths: {strengths}\n",
        "    Weaknesses: {weaknesses}\n",
        "\n",
        "    Please provide:\n",
        "    1. Detailed weekly study plan\n",
        "    2. Recommended learning resources\n",
        "    3. Specific exercises for weaknesses\n",
        "    4. Regular mock test schedule\n",
        "    5. Pre-exam preparation strategy\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1024,\n",
        "            temperature=0.7,\n",
        "            do_sample=True\n",
        "        )\n",
        "    plan = tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, \"\")\n",
        "    return plan\n",
        "\n",
        "def export_history(history):\n",
        "    \"\"\"Export session history as text\"\"\"\n",
        "    if not history:\n",
        "        return \"No conversation history to export\"\n",
        "\n",
        "    try:\n",
        "        from bs4 import BeautifulSoup\n",
        "        import re\n",
        "\n",
        "        # Parsing HTML and extracting text using BeautifulSoup\n",
        "        soup = BeautifulSoup(history, \"html.parser\")\n",
        "        text = soup.get_text()\n",
        "\n",
        "        # Cleaning up the text\n",
        "        cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Returns the cleaned text and timestamp\n",
        "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "        return f\"Conversation exported. Filename: ielts_conversation_{timestamp}.txt\\n\\n{cleaned_text[:100]}...\"\n",
        "    except:\n",
        "        # Simple alternate extraction\n",
        "        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "        return f\"Conversation exported. Filename: ielts_conversation_{timestamp}.txt\"\n",
        "\n",
        "# Improve system architecture diagram generation function\n",
        "def generate_system_diagram():\n",
        "    \"\"\"Generate comprehensive system architecture diagram\"\"\"\n",
        "    from PIL import Image, ImageDraw, ImageFont\n",
        "    import io\n",
        "    import base64\n",
        "    import os\n",
        "\n",
        "    # Create a larger image to show the full content\n",
        "    width, height = 1000, 650\n",
        "    image = Image.new(\"RGB\", (width, height), \"white\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # Try loading a better font\n",
        "    try:\n",
        "        # Try common fonts, depending on the system\n",
        "        font_paths = [\n",
        "            \"arial.ttf\",\n",
        "            \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",\n",
        "            \"/System/Library/Fonts/Helvetica.ttc\"\n",
        "        ]\n",
        "\n",
        "        font = None\n",
        "        for path in font_paths:\n",
        "            if os.path.exists(path):\n",
        "                font = ImageFont.truetype(path, 16)\n",
        "                title_font = ImageFont.truetype(path, 24)\n",
        "                break\n",
        "\n",
        "        if font is None:\n",
        "            font = ImageFont.load_default()\n",
        "            title_font = font\n",
        "    except:\n",
        "        font = ImageFont.load_default()\n",
        "        title_font = font\n",
        "\n",
        "    # Define the main process box\n",
        "    main_flow_boxes = [\n",
        "        {\"x\": 100, \"y\": 150, \"width\": 150, \"height\": 80, \"text\": \"User Query\", \"color\": \"#FFD580\", \"description\": \"Questions about IELTS\"},\n",
        "        {\"x\": 320, \"y\": 150, \"width\": 150, \"height\": 80, \"text\": \"Vector Retrieval\", \"color\": \"#90EE90\", \"description\": \"Embedding search\"},\n",
        "        {\"x\": 540, \"y\": 150, \"width\": 150, \"height\": 80, \"text\": \"Relevant Content\", \"color\": \"#ADD8E6\", \"description\": \"Retrieved materials\"},\n",
        "        {\"x\": 760, \"y\": 150, \"width\": 150, \"height\": 80, \"text\": \"LLM Generation\", \"color\": \"#DDA0DD\", \"description\": \"Gemma-2b-it model\"},\n",
        "        {\"x\": 760, \"y\": 300, \"width\": 150, \"height\": 80, \"text\": \"Result Display\", \"color\": \"#FFCCCB\", \"description\": \"Answer with context\"}\n",
        "    ]\n",
        "\n",
        "    # Define other functional modules\n",
        "    feature_boxes = [\n",
        "        {\"x\": 100, \"y\": 300, \"width\": 150, \"height\": 80, \"text\": \"Writing Assessment\", \"color\": \"#F0E68C\", \"description\": \"Essay evaluation\"},\n",
        "        {\"x\": 320, \"y\": 300, \"width\": 150, \"height\": 80, \"text\": \"Study Plan\", \"color\": \"#98FB98\", \"description\": \"Learning roadmap\"},\n",
        "        {\"x\": 540, \"y\": 300, \"width\": 150, \"height\": 80, \"text\": \"Practice Tests\", \"color\": \"#87CEEB\", \"description\": \"Mock exams\"},\n",
        "        {\"x\": 320, \"y\": 450, \"width\": 150, \"height\": 80, \"text\": \"Text-to-Speech\", \"color\": \"#D8BFD8\", \"description\": \"Voice output\"},\n",
        "        {\"x\": 540, \"y\": 450, \"width\": 150, \"height\": 80, \"text\": \"Progress Tracking\", \"color\": \"#FFB6C1\", \"description\": \"Learning journey\"}\n",
        "    ]\n",
        "\n",
        "    # Draw the main title\n",
        "    title = \"IELTS Learning Assistant System Architecture\"\n",
        "    title_w, title_h = draw.textsize(title, font=title_font) if hasattr(draw, 'textsize') else (width//2, 40)\n",
        "    draw.text(((width - title_w) // 2, 30), title, fill=\"#4B0082\", font=title_font)\n",
        "\n",
        "    # Draw the main process box and description\n",
        "    for box in main_flow_boxes:\n",
        "        x, y = box[\"x\"], box[\"y\"]\n",
        "        w, h = box[\"width\"], box[\"height\"]\n",
        "        draw.rectangle([(x, y), (x+w, y+h)], fill=box[\"color\"], outline=\"#000000\", width=2)\n",
        "\n",
        "        # Adding Main Text\n",
        "        text_w, text_h = draw.textsize(box[\"text\"], font=font) if hasattr(draw, 'textsize') else (w//2, h//3)\n",
        "        text_x = x + (w - text_w) // 2\n",
        "        text_y = y + (h - text_h) // 3\n",
        "        draw.text((text_x, text_y), box[\"text\"], fill=\"#000000\", font=font)\n",
        "\n",
        "        # Add description text\n",
        "        desc_w, desc_h = draw.textsize(box[\"description\"], font=font) if hasattr(draw, 'textsize') else (w//2, h//3)\n",
        "        desc_x = x + (w - desc_w) // 2\n",
        "        desc_y = y + h - text_h - 10\n",
        "        draw.text((desc_x, desc_y), box[\"description\"], fill=\"#333333\", font=font)\n",
        "\n",
        "    # Draw function module boxes and descriptions\n",
        "    for box in feature_boxes:\n",
        "        x, y = box[\"x\"], box[\"y\"]\n",
        "        w, h = box[\"width\"], box[\"height\"]\n",
        "        draw.rectangle([(x, y), (x+w, y+h)], fill=box[\"color\"], outline=\"#000000\", width=2)\n",
        "\n",
        "        # Adding Main Text\n",
        "        text_w, text_h = draw.textsize(box[\"text\"], font=font) if hasattr(draw, 'textsize') else (w//2, h//3)\n",
        "        text_x = x + (w - text_w) // 2\n",
        "        text_y = y + (h - text_h) // 3\n",
        "        draw.text((text_x, text_y), box[\"text\"], fill=\"#000000\", font=font)\n",
        "\n",
        "        # Add description text\n",
        "        desc_w, desc_h = draw.textsize(box[\"description\"], font=font) if hasattr(draw, 'textsize') else (w//2, h//3)\n",
        "        desc_x = x + (w - desc_w) // 2\n",
        "        desc_y = y + h - text_h - 10\n",
        "        draw.text((desc_x, desc_y), box[\"description\"], fill=\"#333333\", font=font)\n",
        "\n",
        "    # Drawing Connection Lines - Main Process\n",
        "    for i in range(len(main_flow_boxes)-2):  # The last frame is processed separately\n",
        "        x1 = main_flow_boxes[i][\"x\"] + main_flow_boxes[i][\"width\"]\n",
        "        y1 = main_flow_boxes[i][\"y\"] + main_flow_boxes[i][\"height\"]//2\n",
        "        x2 = main_flow_boxes[i+1][\"x\"]\n",
        "        y2 = main_flow_boxes[i+1][\"y\"] + main_flow_boxes[i+1][\"height\"]//2\n",
        "\n",
        "        # Lire\n",
        "        draw.line([(x1, y1), (x2, y2)], fill=\"#000000\", width=3)\n",
        "\n",
        "        # Arrow\n",
        "        arrow_size = 10\n",
        "        draw.polygon([(x2-arrow_size, y2-arrow_size//2), (x2, y2), (x2-arrow_size, y2+arrow_size//2)], fill=\"#000000\")\n",
        "\n",
        "    # Connection from LLM Generation to Result Display\n",
        "    llm_idx = 3  # LLM Generation Index\n",
        "    result_idx = 4  #Result Display Index\n",
        "\n",
        "    x1 = main_flow_boxes[llm_idx][\"x\"] + main_flow_boxes[llm_idx][\"width\"]//2\n",
        "    y1 = main_flow_boxes[llm_idx][\"y\"] + main_flow_boxes[llm_idx][\"height\"]\n",
        "    x2 = main_flow_boxes[result_idx][\"x\"] + main_flow_boxes[result_idx][\"width\"]//2\n",
        "    y2 = main_flow_boxes[result_idx][\"y\"]\n",
        "\n",
        "    # Lines and arrows\n",
        "    draw.line([(x1, y1), (x1, y1+30), (x2, y1+30), (x2, y2)], fill=\"#000000\", width=3)\n",
        "    arrow_size = 10\n",
        "    draw.polygon([(x2-arrow_size//2, y2-arrow_size), (x2, y2), (x2+arrow_size//2, y2-arrow_size)], fill=\"#000000\")\n",
        "\n",
        "    # LLM Generation to TTS connection\n",
        "    tts_idx = 3  # Text-to-Speech Index\n",
        "\n",
        "    x1 = main_flow_boxes[llm_idx][\"x\"]\n",
        "    y1 = main_flow_boxes[llm_idx][\"y\"] + main_flow_boxes[llm_idx][\"height\"]//2\n",
        "    x2 = feature_boxes[tts_idx][\"x\"] + feature_boxes[tts_idx][\"width\"]//2\n",
        "    y2 = feature_boxes[tts_idx][\"y\"]\n",
        "\n",
        "    draw.line([(x1, y1), (x1-30, y1), (x1-30, y2-30), (x2, y2-30), (x2, y2)], fill=\"#000000\", width=2)\n",
        "    arrow_size = 10\n",
        "    draw.polygon([(x2-arrow_size//2, y2-arrow_size), (x2, y2), (x2+arrow_size//2, y2-arrow_size)], fill=\"#000000\")\n",
        "\n",
        "    #Add a legend\n",
        "    legend_y = 580\n",
        "    legend_items = [\n",
        "        {\"text\": \"Main Process Flow\", \"color\": \"#000000\", \"width\": 3},\n",
        "        {\"text\": \"Additional Features\", \"color\": \"#000000\", \"width\": 2},\n",
        "    ]\n",
        "\n",
        "    for i, item in enumerate(legend_items):\n",
        "        x_pos = 100 + i * 300\n",
        "        # Line\n",
        "        draw.line([(x_pos, legend_y), (x_pos + 50, legend_y)], fill=item[\"color\"], width=item[\"width\"])\n",
        "        # text\n",
        "        draw.text((x_pos + 60, legend_y - 5), item[\"text\"], fill=\"#000000\", font=font)\n",
        "\n",
        "    # Add bottom note\n",
        "    footer_text = \"Built with SentenceTransformer, Google Gemma-2b-it, and Facebook MMS-TTS-Eng\"\n",
        "    footer_w, footer_h = draw.textsize(footer_text, font=font) if hasattr(draw, 'textsize') else (width//2, 20)\n",
        "    draw.text(((width - footer_w) // 2, height - 30), footer_text, fill=\"#666666\", font=font)\n",
        "\n",
        "    return image\n",
        "\n",
        "# 4. Creating the Gradio Interface\n",
        "def create_interface():\n",
        "    \"\"\"Creating the Gradio Interface\"\"\"\n",
        "    with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "        with gr.Tab(\"Main Application\"):\n",
        "            gr.Markdown(\"# IELTS Learning Assistant\")\n",
        "            gr.Markdown(\"\"\"\n",
        "            This application uses artificial intelligence to answer questions about the IELTS exam. It is based on IELTS textbook content and can help you understand key aspects of the exam and improve your skills.\n",
        "\n",
        "            **Language Support**:\n",
        "            - Text-to-speech functionality is only available for English\n",
        "            \"\"\")\n",
        "\n",
        "            # User Information\n",
        "            with gr.Row():\n",
        "                username_input = gr.Textbox(\n",
        "                    label=\"Username\",\n",
        "                    placeholder=\"Enter your username to track learning progress\",\n",
        "                    value=\"default_user\"\n",
        "                )\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=2):\n",
        "                    query_input = gr.Textbox(\n",
        "                        label=\"Question\",\n",
        "                        placeholder=\"Enter your question about the IELTS exam...\",\n",
        "                        lines=2\n",
        "                    )\n",
        "                    with gr.Row():\n",
        "                        submit_btn = gr.Button(\"Submit\", variant=\"primary\")\n",
        "                        clear_btn = gr.Button(\"Clear\")\n",
        "\n",
        "                    response_output = gr.Textbox(\n",
        "                        label=\"Answer\",\n",
        "                        lines=10,\n",
        "                        placeholder=\"AI's answer will appear here...\",\n",
        "                    )\n",
        "\n",
        "                    # New: Independent performance indicator display\n",
        "                    metrics_output = gr.Markdown(label=\"Performance Metrics\")\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    with gr.Accordion(\"References\", open=False):\n",
        "                        context_output = gr.Markdown()\n",
        "\n",
        "            # Session History\n",
        "            with gr.Accordion(\"Conversation History\", open=False):\n",
        "                history_display = gr.HTML()\n",
        "                with gr.Row():\n",
        "                    export_btn = gr.Button(\"Export Conversation\")\n",
        "                    clear_history_btn = gr.Button(\"Clear History\")\n",
        "                export_status = gr.Textbox(label=\"Export Status\", visible=False)\n",
        "\n",
        "            # Example Question\n",
        "            examples = [\n",
        "                [\"How can I improve my IELTS listening score?\"],\n",
        "                [\"What is the ideal structure for IELTS Writing Task 2?\"],\n",
        "                [\"How to manage time effectively in the IELTS reading test?\"],\n",
        "                [\"What should I pay attention to in the IELTS speaking test?\"],\n",
        "                [\"What are the common mistakes in IELTS Writing Task 1?\"],\n",
        "                [\"How to achieve band 7+ in IELTS?\"]\n",
        "            ]\n",
        "\n",
        "            # Setup Events - Updated to use tracking and history\n",
        "            submit_btn.click(\n",
        "                fn=process_query_with_history,\n",
        "                inputs=[query_input, history_display],\n",
        "                outputs=[response_output, context_output, metrics_output, history_display]\n",
        "            )\n",
        "            clear_btn.click(\n",
        "                lambda: [\"\", \"\", \"\"],\n",
        "                outputs=[query_input, response_output, metrics_output]\n",
        "            )\n",
        "            export_btn.click(\n",
        "                fn=export_history,\n",
        "                inputs=history_display,\n",
        "                outputs=export_status\n",
        "            )\n",
        "            clear_history_btn.click(\n",
        "                lambda: \"\",\n",
        "                outputs=history_display\n",
        "            )\n",
        "            gr.Examples(\n",
        "                examples=examples,\n",
        "                inputs=query_input\n",
        "            )\n",
        "\n",
        "            # Adding text-to-speech functionality\n",
        "            with gr.Accordion(\"Text-to-Speech Feature\", open=False):\n",
        "                gr.Markdown(\"## Convert Text to Speech\")\n",
        "                gr.Markdown(\"Enter English text or use the answer content to convert to speech.\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    text_for_tts = gr.Textbox(\n",
        "                        label=\"Text to convert to speech\",\n",
        "                        lines=2,\n",
        "                        placeholder=\"Enter English text to convert to speech...\"\n",
        "                    )\n",
        "                    with gr.Column():\n",
        "                        convert_btn = gr.Button(\"Convert Text\", variant=\"secondary\")\n",
        "                        convert_response_btn = gr.Button(\"Convert Answer\", variant=\"secondary\")\n",
        "\n",
        "                audio_output = gr.Audio(label=\"Speech Output\")\n",
        "                tts_status = gr.Markdown()  # Add status information display\n",
        "\n",
        "                # Connecting TTS Function\n",
        "                convert_btn.click(\n",
        "                    fn=tts_with_language_check,\n",
        "                    inputs=text_for_tts,\n",
        "                    outputs=[audio_output, tts_status]\n",
        "                )\n",
        "                convert_response_btn.click(\n",
        "                    fn=tts_with_language_check,\n",
        "                    inputs=response_output,\n",
        "                    outputs=[audio_output, tts_status]\n",
        "                )\n",
        "\n",
        "            # Add learning progress display\n",
        "            view_progress_btn = gr.Button(\"View Learning Progress\")\n",
        "            progress_display = gr.Markdown(label=\"Learning Progress\")\n",
        "\n",
        "            view_progress_btn.click(\n",
        "                fn=lambda username: track_user_activity(username, \"query\", \"View progress\"),\n",
        "                inputs=username_input,\n",
        "                outputs=progress_display\n",
        "            )\n",
        "\n",
        "        # Writing Grading Tab\n",
        "        with gr.Tab(\"Writing Assessment\"):\n",
        "            gr.Markdown(\"# IELTS Writing Assessment\")\n",
        "            gr.Markdown(\"Upload your IELTS writing sample to get professional scoring and feedback.\")\n",
        "\n",
        "            writing_username = gr.Textbox(\n",
        "                label=\"Username\",\n",
        "                placeholder=\"Enter your username to track progress\",\n",
        "                value=\"default_user\"\n",
        "            )\n",
        "\n",
        "            writing_input = gr.Textbox(\n",
        "                label=\"Paste your IELTS writing sample\",\n",
        "                placeholder=\"Paste your Task 1 or Task 2 writing here...\",\n",
        "                lines=10\n",
        "            )\n",
        "            evaluate_btn = gr.Button(\"Get Assessment\", variant=\"primary\")\n",
        "            evaluation_output = gr.Markdown(label=\"Scoring and Feedback\")\n",
        "            writing_progress = gr.Markdown(label=\"Writing Progress\")\n",
        "\n",
        "            # Updated writing grades to track progress\n",
        "            def evaluate_with_tracking(sample, username):\n",
        "                feedback = evaluate_ielts_writing(sample, username)\n",
        "                progress = track_user_activity(username, \"writing\", sample)\n",
        "                return feedback, progress\n",
        "\n",
        "            evaluate_btn.click(\n",
        "                fn=evaluate_with_tracking,\n",
        "                inputs=[writing_input, writing_username],\n",
        "                outputs=[evaluation_output, writing_progress]\n",
        "            )\n",
        "\n",
        "        # Added mock exam tab\n",
        "        with gr.Tab(\"Practice Tests\"):\n",
        "            gr.Markdown(\"# IELTS Practice Tests\")\n",
        "            gr.Markdown(\"Select an exam section to generate corresponding practice questions.\")\n",
        "\n",
        "            practice_username = gr.Textbox(\n",
        "                label=\"Username\",\n",
        "                placeholder=\"Enter your username to track progress\",\n",
        "                value=\"default_user\"\n",
        "            )\n",
        "\n",
        "            section_selector = gr.Dropdown(\n",
        "                label=\"Select Exam Section\",\n",
        "                choices=[\"Listening\", \"Reading\", \"Writing\", \"Speaking\"],\n",
        "                value=\"Writing\"\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\"Generate Practice Question\", variant=\"primary\")\n",
        "            practice_output = gr.Markdown(label=\"Practice Question\")\n",
        "\n",
        "            # Generate mock questions and track activity\n",
        "            def generate_practice_with_tracking(section, username):\n",
        "                practice = generate_practice_question(section)\n",
        "                # Record this mock exam activity\n",
        "                track_user_activity(username, \"practice\", section)\n",
        "                return practice\n",
        "\n",
        "            generate_btn.click(\n",
        "                fn=generate_practice_with_tracking,\n",
        "                inputs=[section_selector, practice_username],\n",
        "                outputs=practice_output\n",
        "            )\n",
        "\n",
        "        # Add a learning plan tab\n",
        "        with gr.Tab(\"Study Plan\"):\n",
        "            gr.Markdown(\"# Personalized IELTS Study Plan\")\n",
        "            gr.Markdown(\"Input your goals and conditions to get a customized IELTS study plan.\")\n",
        "\n",
        "            with gr.Row():\n",
        "                target_score = gr.Slider(\n",
        "                    label=\"Target Overall Score\",\n",
        "                    minimum=5.0,\n",
        "                    maximum=9.0,\n",
        "                    step=0.5,\n",
        "                    value=7.0\n",
        "                )\n",
        "                weeks = gr.Slider(\n",
        "                    label=\"Available Study Weeks\",\n",
        "                    minimum=1,\n",
        "                    maximum=24,\n",
        "                    step=1,\n",
        "                    value=8\n",
        "                )\n",
        "\n",
        "            strengths = gr.Textbox(\n",
        "                label=\"Your Strengths\",\n",
        "                placeholder=\"e.g.: Listening, Reading...\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            weaknesses = gr.Textbox(\n",
        "                label=\"Areas to Improve\",\n",
        "                placeholder=\"e.g.: Writing, Speaking...\",\n",
        "                lines=2\n",
        "            )\n",
        "\n",
        "            plan_btn = gr.Button(\"Generate Study Plan\", variant=\"primary\")\n",
        "            plan_output = gr.Markdown(label=\"Personalized Study Plan\")\n",
        "\n",
        "            plan_btn.click(\n",
        "                fn=generate_study_plan,\n",
        "                inputs=[target_score, weeks, strengths, weaknesses],\n",
        "                outputs=plan_output\n",
        "            )\n",
        "\n",
        "        # System Architecture Tab\n",
        "        with gr.Tab(\"System Architecture\"):\n",
        "            with gr.Row():\n",
        "                gr.Markdown(\"# IELTS Learning Assistant System Architecture\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"\"\"\n",
        "        ## Overall Architecture\n",
        "        This system uses Retrieval-Augmented Generation (RAG) combined with Text-to-Speech (TTS) technology to provide IELTS learning assistance.\n",
        "\n",
        "        ## How This System Works\n",
        "\n",
        "        This IELTS Learning Assistant uses a powerful combination of **Retrieval-Augmented Generation (RAG)** and **Text-to-Speech** technology to provide accurate, contextually relevant responses to your IELTS questions.\n",
        "\n",
        "        The system follows these steps:\n",
        "        1. When you ask a question, it's converted to a vector representation\n",
        "        2. This vector is compared against our IELTS materials database\n",
        "        3. The most relevant content is retrieved\n",
        "        4. The AI combines this content with its own knowledge to generate a helpful answer\n",
        "        5. If relevance is low, the AI relies more on its own knowledge\n",
        "\n",
        "        All answers are based on standard IELTS curriculum materials and best practices in IELTS preparation.\n",
        "        \"\"\")\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"\"\"\n",
        "        ## Components\n",
        "        1. **Data Preprocessing Module**\n",
        "          - Splits IELTS textbook materials into semantic chunks\n",
        "          - Generates embedding vectors using SentenceTransformer\n",
        "          - Stores text chunks and corresponding embedding vectors\n",
        "\n",
        "        2. **Retrieval Module**\n",
        "          - Uses vector similarity search\n",
        "          - Calculates similarity based on all-mpnet-base-v2 model\n",
        "          - Selects the N most relevant text chunks\n",
        "\n",
        "        3. **Generation Module**\n",
        "          - Uses Google Gemma-2b-it model\n",
        "          - Constructs context prompts based on retrieved content\n",
        "          - Generates answers based on relevance threshold\n",
        "\n",
        "        4. **Text-to-Speech Module**\n",
        "          - Uses Facebook MMS-TTS-Eng model\n",
        "          - Converts generated text to natural speech\n",
        "        \"\"\")\n",
        "\n",
        "            # Display the enhanced system diagram\n",
        "            gr.Image(value=generate_system_diagram(), label=\"System Flow Diagram\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"\"\"\n",
        "        ## Learning & Assessment Components\n",
        "\n",
        "        5. **Writing Assessment Module**\n",
        "          - Evaluates IELTS writing using large language model\n",
        "          - Provides detailed scoring and improvement suggestions\n",
        "\n",
        "        6. **Study Plan Module**\n",
        "          - Generates personalized learning plans based on user goals and time\n",
        "          - Provides targeted learning suggestions and resource recommendations\n",
        "        \"\"\")\n",
        "\n",
        "                with gr.Column(scale=1):\n",
        "                    gr.Markdown(\"\"\"\n",
        "        7. **Practice Test Module**\n",
        "          - Generates IELTS practice questions for each section\n",
        "          - Helps users familiarize with test format and content\n",
        "\n",
        "        8. **Learning Progress Tracking**\n",
        "          - Records user learning activities and achievements\n",
        "          - Provides visualization of learning journey\n",
        "        \"\"\")\n",
        "\n",
        "            with gr.Accordion(\"Technical Details\", open=False):\n",
        "                gr.Markdown(\"\"\"\n",
        "        ### Implementation Details\n",
        "\n",
        "        **Models Used:**\n",
        "        - **Embedding Model**: SentenceTransformer (all-mpnet-base-v2)\n",
        "        - **Language Model**: Google Gemma-2b-it (2 billion parameters)\n",
        "        - **TTS Model**: Facebook MMS-TTS-Eng\n",
        "\n",
        "        **RAG Implementation:**\n",
        "        ```python\n",
        "        # Vector search with relevance threshold\n",
        "        def retrieve_relevant_resources(query, embeddings, n_resources=5):\n",
        "            query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "            dot_scores = util.dot_score(query_embedding, embeddings)[0]\n",
        "            scores, indices = torch.topk(dot_scores, k=n_resources)\n",
        "            return scores, indices\n",
        "\n",
        "        # Dynamic prompt selection based on relevance\n",
        "        def generate_answer(query, context_items, avg_relevance_score=0.0):\n",
        "            # Use threshold to decide prompt strategy\n",
        "            relevance_threshold = 0.65\n",
        "\n",
        "            if avg_relevance_score < relevance_threshold:\n",
        "                # Low relevance - rely on model knowledge\n",
        "                prompt = \"Here is a question about the IELTS exam. Since no sufficiently relevant reference materials were found, please use your own knowledge to answer.\\\\n\\\\nQuestion: \" + query + \"\\\\n\\\\nAnswer:\"\n",
        "            else:\n",
        "                # High relevance - use retrieved content\n",
        "                context = \"\\\\n\\\\n\".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "                prompt = \"Based on the following IELTS materials, answer the question:\\\\n\\\\nContent:\\\\n\" + context + \"\\\\n\\\\nQuestion: \" + query + \"\\\\n\\\\nAnswer:\"\n",
        "                \"\"\")\n",
        "    return demo\n",
        "\n",
        "# 5. Startup interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo = create_interface()\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640,
          "referenced_widgets": [
            "bd26ff78ff5f44029175424f0d4a13de",
            "80f3c9e15cfa498695d7559c00a20cdd",
            "582e921d5506441cae0201135e1a4cc2",
            "92cd7a9e138b40b9934dcb6b4579c057",
            "8bac813fb8f94dda9852780e26ada314",
            "ac90319ce3b64d7f914a2e0a6667c07f",
            "b4d1e5edd492478bb9a37beb40348a48",
            "d727cef20dfa46bd889aba4b87b844cd",
            "d2551f3a2d5e4e7c904cb7a1e16d2bf9",
            "ecadf3d681104f19ae28469679e02f3d",
            "cb35f026286d4cfda3ece6dabd9fe9b4"
          ]
        },
        "id": "Z91VpUNlcZNU",
        "outputId": "3e749a1e-c0f9-4816-bb5f-b9c2a754bb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully loaded data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd26ff78ff5f44029175424f0d4a13de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e60a11c6369c472413.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e60a11c6369c472413.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}